<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="RS,GPS,GIS,QGIS,Opticks,QT,OpenCV,OSG" />
       
      <meta name="description" content="地理信息系统，遥感科学，卫星导航定位技术综合研究。" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> 帕拉丁的游鱼</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="/atom.xml" title="帕拉丁的游鱼" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">帕拉丁的游鱼</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['面朝大海，春暖花开', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Accept-Encoding"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/20/Accept-Encoding/"
    >Accept-Encoding</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/20/Accept-Encoding/" class="article-date">
  <time datetime="2023-04-20T09:01:58.000Z" itemprop="datePublished">2023-04-20</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="一、项目经历"><a href="#一、项目经历" class="headerlink" title="一、项目经历"></a>一、项目经历</h1><p>碰到个奇葩的服务，请求头加了Accept-Encoding，但凡结果不为空的，就报异常，结果为空的就给放行说成功。</p>
<h1 id="二、同行遭遇"><a href="#二、同行遭遇" class="headerlink" title="二、同行遭遇"></a>二、同行遭遇</h1><h2 id="1、请求头设置-Accept-Encoding"><a href="#1、请求头设置-Accept-Encoding" class="headerlink" title="1、请求头设置 Accept-Encoding"></a>1、请求头设置 Accept-Encoding</h2><pre><code>&quot;Accept-Encoding&quot;: &quot;gzip, deflate, br&quot;
</code></pre>
<p>返回的数据是乱码，无论设置utf-8、gbk、gb2312都无法解码</p>
<p>一个奇怪的现象是本地测试可以正常解码，代码在服务器上运行就无法解码，最终将该请求头去除就正常了。</p>
<p>在使用okhttp请求服务器数据的时候，发现返回的数据一直都是乱码，但是使用fiddler抓包，decode后，可以正常显示。刚开始一直怀疑是编码的问题，后来对比了hex的数据和程序中乱码的二进制，发现不一样。fiddler可以自动处理，说明不是密钥加密。经过不断的尝试发现时Accept-Encoding设置的问题，下面就一一详细介绍一下</p>
<h2 id="2、设置Accept-Encoding为gzip-deflate，返回的网页是乱码"><a href="#2、设置Accept-Encoding为gzip-deflate，返回的网页是乱码" class="headerlink" title="2、设置Accept-Encoding为gzip,deflate，返回的网页是乱码"></a>2、设置Accept-Encoding为gzip,deflate，返回的网页是乱码</h2><ul>
<li>HTTP 内容协商</li>
</ul>
<p>要了解 Vary 的作用，先得了解 HTTP 的内容协商机制。有时候，同一个 URL 可以提供多份不同的文档，这就要求服务端和客户端之间有一个选择最合适版本的机制，这就是内容协商。</p>
<ul>
<li>协商方式有两种</li>
</ul>
<p>一种是服务端把文档可用版本列表发给客户端让用户选，这可以使用 300 Multiple Choices 状态码来实现。这种方案有不少问题，首先多一次网络往返；其次服务端同一文档的某些版本可能是为拥有某些技术特征的客户端准备的，而普通用户不一定了解这些细节。举个例子，服务端通常可以将静态资源输出为压缩和未压缩两个版本，压缩版显然是为支持压缩的客户端而准备的，但如果让普通用户选，很可能选择错误的版本。</p>
<p>另外一种方案：服务端根据客户端发送的请求头中某些字段自动发送最合适的版本。可以用于这个机制的请求头字段又分两种：内容协商专用字段（Accept 字段）、其他字段。HTTP 的内容协商通常使用这个方案</p>
<pre><code>请求头字段    说明    响应头字段
Accept    告知服务器发送何种媒体类型    Content-Type
Accept-Language    告知服务器发送何种语言    Content-Language
Accept-Charset    告知服务器发送何种字符集    Content-Type
Accept-Encoding    告知服务器采用何种压缩方式    Content-Encoding
</code></pre>
<p>例如客户端发送以下请求头：</p>
<pre><code>Accept:*/*
Accept-Encoding:gzip,deflate,sdch
Accept-Language:zh-CN,en-US;q=0.8,en;q=0.6
</code></pre>
<p>表示它可以接受任何 MIME 类型的资源；支持采用 gzip、deflate 或 sdch 压缩过的资源；可以接受 zh-CN、en-US 和 en 三种语言，并且 zh-CN 的权重最高（q 取值 0 - 1，最高为 1，最低为 0，默认为 1），服务端应该优先返回语言等于 zh-CN 的版本。</p>
<p>浏览器的响应头可能是这样的：</p>
<pre><code>Content-Type: text/javascript
Content-Encoding: gzip
</code></pre>
<p>表示这个文档确切的 MIME 类型是 text/javascript；文档内容进行了 gzip 压缩；响应头没有 Content-Language 字段，通常说明返回版本的语言正好是请求头 Accept-Language 中权重最高的那个。</p>
<p>有时候，上面四个 Accept 字段并不够用，例如要针对特定浏览器如 IE6 输出不一样的内容，就需要用到请求头中的 User-Agent 字段。类似的，请求头中的 Cookie 也可能被服务端用做输出差异化内容的依据。</p>
<p>由于客户端和服务端之间可能存在一个或多个中间实体（如缓存服务器），而缓存服务最基本的要求是给用户返回正确的文档。如果服务端根据不同 User-Agent 返回不同内容，而缓存服务器把 IE6 用户的响应缓存下来，并返回给使用其他浏览器的用户，肯定会出问题 。</p>
<p>所以 HTTP 协议规定，如果服务端提供的内容取决于 User-Agent 这样「常规 Accept 协商字段之外」的请求头字段，那么响应头中必须包含 Vary 字段，且 Vary 的内容必须包含 User-Agent。同理，如果服务端同时使用请求头中 User-Agent 和 Cookie 这两个字段来生成内容，那么响应中的 Vary 字段看上去应该是这样的：</p>
<pre><code>Vary: User-Agent, Cookie
</code></pre>
<p>也就是说 Vary 字段用于列出一个响应字段列表，告诉缓存服务器遇到同一个 URL 对应着不同版本文档的情况时，如何缓存和筛选合适的版本。</p>
<ul>
<li><p>在Okhttp中的解决方法<br>上面返回乱码的原因就是没有正确解压Gzip的数据，</p>
</li>
<li><p>分析：<br>在 Okhttp 中，如果在请求头添加addHeader(“Accept-Encoding”, “gzip, deflate”)，Okhttp 不会帮你处理Gzip的解压，需要你自己去处理。</p>
</li>
</ul>
<p>部分源码如下：</p>
<pre><code>boolean transparentGzip = false;
if (userRequest.header(&quot;Accept-Encoding&quot;) == null)
&#123;
  transparentGzip = true;
  requestBuilder.header(&quot;Accept-Encoding&quot;, &quot;gzip&quot;);
&#125;

if (transparentGzip &amp;&amp;
 &quot;gzip&quot;.equalsIgnoreCase(networkResponse.header(&quot;Content-Encoding&quot;))
    &amp;&amp; HttpHeaders.hasBody(networkResponse))
&#123;
  GzipSource responseBody = new GzipSource(networkResponse.body().source());
  Headers strippedHeaders = networkResponse.headers().newBuilder()
      .removeAll(&quot;Content-Encoding&quot;)
      .removeAll(&quot;Content-Length&quot;)
      .build();
  responseBuilder.headers(strippedHeaders);
  responseBuilder.body(new RealResponseBody(strippedHeaders, Okio.buffer(responseBody)));
&#125;
</code></pre>
<ul>
<li>解决方法：<br>把Request的header中去掉header(“Accept-Encoding”)就行了</li>
</ul>
<p>通过Request.Builder.tag(“url”)来打tag，然后通过下述代码即可做到cancel某一个Request的功能，你需要做的只是返回url就行了。</p>
<pre><code>public static void cancelCallWithTag(String tag) &#123;
    for (Call call : RequestApi2.getInstance().getOkHttpClient().dispatcher().queuedCalls()) &#123;
        if (call.request().tag().equals(tag))
            call.cancel();
    &#125;
    for (Call call : RequestApi2.getInstance().getOkHttpClient().dispatcher().runningCalls()) &#123;
        if (call.request().tag().equals(tag))
            call.cancel();
    &#125;
&#125;
</code></pre>
<p>有朋友可能想到，如果在header添加”Accept-Encoding”, “gzip, deflate”，返回的是gzip压缩的数据，自己解压可不可以？<br>使用其他的http库，可以拿到最原始的http数据，是可以的。但使用okhttp，返回的字符串是经过编码的，此时已经不是gzip数据格式了，所以没法解压。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/JAVA/" rel="tag">JAVA</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-Axure下载及汉化"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/19/Axure%E4%B8%8B%E8%BD%BD%E5%8F%8A%E6%B1%89%E5%8C%96/"
    >Axure RP下载及汉化</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/19/Axure%E4%B8%8B%E8%BD%BD%E5%8F%8A%E6%B1%89%E5%8C%96/" class="article-date">
  <time datetime="2023-04-19T02:48:47.000Z" itemprop="datePublished">2023-04-19</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/">知识分享</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Axure-RP"><a href="#Axure-RP" class="headerlink" title="Axure RP"></a>Axure RP</h1><p>Axure RP 是一款专业的快速原型设计工具。Axure（发音：Ack-sure），代表美国Axure公司；RP则是Rapid Prototyping（快速原型）的缩写。<br>Axure RP 是美国Axure Software Solution 公司旗舰产品，是一个专业的快速原型设计工具，让负责定义需求和规格、设计功能和界面的专家能够快速创建应用软件或Web网站的线框图、流程图、原型和规格说明文档。</p>
<p>作为专业的原型设计工具，它能快速、高效的创建原型，同时支持多人协作设计和版本控制管理。<br>Axure RP 的使用者主要包括商业分析师、信息架构师、产品经理、IT咨询师、用户体验设计师、交互设计师、UI设计师等，另外，架构师、程序员也在使用Axure。</p>
<h1 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h1><p><a target="_blank" rel="noopener" href="https://www.axure.com/release-history">https://www.axure.com/release-history</a><br><a target="_blank" rel="noopener" href="https://www.axure.com/release-history/rp8">https://www.axure.com/release-history/rp8</a><br><a target="_blank" rel="noopener" href="https://www.axure.com/release-history/rp9">https://www.axure.com/release-history/rp9</a><br><a target="_blank" rel="noopener" href="https://www.axure.com/release-history/rp7">https://www.axure.com/release-history/rp7</a></p>
<h1 id="汉化资源"><a href="#汉化资源" class="headerlink" title="汉化资源"></a>汉化资源</h1><p>Axure中文网<br><a target="_blank" rel="noopener" href="https://www.axure.com.cn/78629">https://www.axure.com.cn/78629</a><br><a target="_blank" rel="noopener" href="https://www.axure.com.cn/84384">https://www.axure.com.cn/84384</a></p>
<p>汉化资源使用方法，以 Axure RP 9 为例：</p>
<ul>
<li><p>【使用方法】<br>1、将汉化压缩包解压缩。<br>2、将解压缩后的【lang文件夹】复制粘贴到软件安装根目录下。</p>
</li>
<li><p>【Windows系统汉化路径】<br>以Win7-64位系统为例：C:\Program Files (x86)\Axure\Axure RP 9</p>
</li>
<li><p>【Mac系统汉化路径】<br>以中文版为例：前往–应用程序–右键点击程序图标–显示包内容，依次打开文件夹：Contents&gt;Resources&gt;</p>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Axure-RP/" rel="tag">Axure RP</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-数据结构浅谈（一）"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B5%85%E8%B0%88%EF%BC%88%E4%B8%80%EF%BC%89/"
    >数据结构浅谈（一）</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B5%85%E8%B0%88%EF%BC%88%E4%B8%80%EF%BC%89/" class="article-date">
  <time datetime="2023-04-18T04:16:47.000Z" itemprop="datePublished">2023-04-18</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>数据结构主要描述数据之间的关系，每一个数据可以称之为数据元素，一般以结构体或类来描述。</p>
<p>数据元素的内部组成，一般基础数据类型或复合数据类型。<br>基础数据类型大体可以分为：数值型,字符串型和日期时间型。复合数据类型又分为结构体、联合体。</p>
<p>数据元素之间的关系，从表现形式来看，可以分为四种：离散结构、线性结构、树形结构、图形结构。从组织方式来看，可以分为两种：数组和链表。</p>
<p>一般研究讨论的都是线性结构、树形结构、图形结构。<br>1、线性结构：元素之间是“一对一”的关系，典型有：队列、栈。<br>2、树形结构：元素之间是“一对多”的关系，典型有：树，堆。<br>3、图形结构：元素之间是“多对多”的关系。</p>
<p>数组是申请连续的数据块，查找快捷。链表则是离散数据块，元素之间要记录相互关系，增删方便，</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-MySQL性能优化"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/17/MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"
    >MySQL性能优化</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/17/MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" class="article-date">
  <time datetime="2023-04-17T06:39:30.000Z" itemprop="datePublished">2023-04-17</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E9%83%A8%E7%BD%B2%E8%BF%90%E7%BB%B4/">部署运维</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="使用-Explain-进行分析"><a href="#使用-Explain-进行分析" class="headerlink" title="使用 Explain 进行分析"></a>使用 Explain 进行分析</h1><p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。</p>
<p>比较重要的字段有:<br>select_type : 查询类型，有简单查询、联合查询、子查询等<br>key : 使用的索引<br>rows : 扫描的行数</p>
<h1 id="优化数据访问"><a href="#优化数据访问" class="headerlink" title="优化数据访问"></a>优化数据访问</h1><h2 id="1-减少请求的数据量"><a href="#1-减少请求的数据量" class="headerlink" title="1. 减少请求的数据量"></a>1. 减少请求的数据量</h2><p>只返回必要的列: 最好不要使用 SELECT * 语句。<br>只返回必要的行: 使用 LIMIT 语句来限制返回的数据。<br>缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。</p>
<h2 id="2-减少服务器端扫描的行数"><a href="#2-减少服务器端扫描的行数" class="headerlink" title="2. 减少服务器端扫描的行数"></a>2. 减少服务器端扫描的行数</h2><p>最有效的方式是使用索引来覆盖查询。</p>
<h3 id="重构查询方式"><a href="#重构查询方式" class="headerlink" title="重构查询方式"></a>重构查询方式</h3><ul>
<li><ol>
<li>切分大查询</li>
</ol>
</li>
</ul>
<p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。</p>
<pre><code>DELEFT FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH);

rows_affected = 0
do &#123;
    rows_affected = do_query(
    &quot;DELETE FROM messages WHERE create  &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000&quot;)
&#125; while rows_affected &gt; 0
</code></pre>
<ul>
<li><ol start="2">
<li>分解大连接查询</li>
</ol>
</li>
</ul>
<p>将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有:让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。减少锁竞争；在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</p>
<pre><code>SELECT * FROM tab
    JOIN tag_post ON tag_post.tag_id=tag.id
    JOIN post ON tag_post.post_id=post.id
    WHERE tag.tag=&#39;mysql&#39;;

SELECT * FROM tag WHERE tag=&#39;mysql&#39;;
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
</code></pre>
<hr>
<p>著作权归@pdai所有<br>原文链接：<a target="_blank" rel="noopener" href="https://pdai.tech/md/db/sql-mysql/sql-mysql-performance.html">https://pdai.tech/md/db/sql-mysql/sql-mysql-performance.html</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MySQL/" rel="tag">MySQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%83%A8%E7%BD%B2%E8%BF%90%E7%BB%B4/" rel="tag">部署运维</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-Oracle性能分析总结"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/16/Oracle%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/"
    >Oracle性能分析总结（转载）</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/16/Oracle%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93/" class="article-date">
  <time datetime="2023-04-16T06:10:19.000Z" itemprop="datePublished">2023-04-16</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E9%83%A8%E7%BD%B2%E8%BF%90%E7%BB%B4/">部署运维</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>关于Oracle的性能调整，一般包括两个方面。</p>
<p>一是指Oracle数据库本身的调整，比如SGA、PGA的优化设置，</p>
<p>二是连接Oracle的应用程序以及SQL语句的优化。</p>
<p>做好这两个方面的优化，就可以使一套完整的Oracle应用系统处于良好的运行状态。</p>
<p>本文主要是把一些OracleTuning的文章作了一个简单的总结，力求以实际可操作为目的，配合讲解部分理论知识，使大部分具有一般Oracle知识的使用者能够对Oracle Tuning有所了解，并且能够根据实际情况对某些参数进行调整。关于更加详细的知识，请参见本文结束部分所提及的推荐书籍，同时由于该话题内容太多且复杂，本文必定有失之偏颇甚至错误的地方，请不吝赐教，并共同进步。</p>
<ol>
<li> SGA的设置<br>在OracleTuning中，对SGA的设置是关键。SGA，是指Shared Global Area , 或者是System Global Area , 称为共享全局区或者系统全局区，结构如下图所示。</li>
</ol>
<p>对于SGA区域内的内存来说，是共享的、全局的，在UNIX 上，必须为oracle 设置共享内存段（可以是一个或者多个），因为oracle 在UNIX上是多进程；而在WINDOWS上oracle是单进程（多个线程），所以不用设置共享内存段。</p>
<p>1.1  SGA的各个组成部分<br>下面用 sqlplus 查询举例看一下 SGA 各个组成部分的情况：</p>
<pre><code>SQL&gt; select * from v$sga;
NAME                     VALUE
--------------------             ----------
FixedSize                  104936
VariableSize             823164928
Database Buffers         1073741824
RedoBuffers                172032
</code></pre>
<p>或者</p>
<pre><code>SQL&gt; show sga
Total System Global Area   1897183720 bytes
FixedSize                  104936 bytes
VariableSize             823164928 bytes
Database Buffers         1073741824 bytes
RedoBuffers                172032 bytes
</code></pre>
<p>Fixed Size</p>
<p>oracle 的不同平台和不同版本下可能不一样，但对于确定环境是一个固定的值，里面存储了SGA 各部分组件的信息，可以看作引导建立SGA的区域。</p>
<p>Variable Size</p>
<p>包含了shared_pool_size、java_pool_size、large_pool_size 等内存设置</p>
<p>Database Buffers</p>
<p>指数据缓冲区，在8i 中包含db_block_buffer*db_block_size、buffer_pool_keep、buffer_pool_recycle 三部分内存。在9i 中包含db_cache_size、db_keep_cache_size、db_recycle_cache_size、db_nk_cache_size。</p>
<p>Redo Buffers</p>
<p>指日志缓冲区，log_buffer。在这里要额外说明一点的是，对于v$parameter、v$sgastat、v$sga查询值可能不一样。v$ parameter 里面的值，是指用户在初始化参数文件里面设置的值，v$sgastat是oracle 实际分配的日志缓冲区大小（因为缓冲区的分配值实际上是离散的，也不是以block 为最小单位进行分配的），v$sga 里面查询的值，是在oracle 分配了日志缓冲区后，为了保护日志缓冲区，设置了一些保护页，通常我们会发现保护页大小是8k(不同环境可能不一样)。参考如下内容</p>
<pre><code>SQL&gt; select substr(name,1,10) name,substr(value,1,10) value
       2 from v$parameter where name =&#39;log_buffer&#39;;
NAME                VALUE
--------------------  --------------------
log_buffer             163840

SQL&gt; select * from v$sgastat where pool is null;

POOL       NAME                      BYTES
-------------------------------------               ----------
           fixed_sga                     104936
           db_block_buffers           1073741824
           log_buffer                    163840

SQL&gt; select * from v$sga;

NAME                     VALUE
--------------------             ----------
FixedSize                  104936
VariableSize              823164928
Database Buffers          1073741824
RedoBuffers                172032
</code></pre>
<p>172032 – 163840 = 8192</p>
<p>（以上试验数据是在 HPB.11.11 + Oracle 8.1.7.4 环境下得到的）</p>
<p>1.2  SGA的大小设置</p>
<p>在对SGA的结构进行简单分析以后，下面是关于如何根据系统的情况正确设置SGA大小的问题。<br>SGA是一块内存区域，占用的是系统物理内存，因此对于一个Oracle应用系统来说，SGA决不是越大越好，这就需要寻找一个系统优化的平衡点。</p>
<p>1.2.1  设置参数前的准备<br>在设置SGA的内存参数之前，我们首先要问自己几个问题<br>一：物理内存多大<br>二：操作系统估计需要使用多少内存<br>三：数据库是使用文件系统还是裸设备<br>四：有多少并发连接<br>五：应用是OLTP 类型还是OLAP 类型</p>
<p>根据这几个问题的答案，我们可以粗略地为系统估计一下内存设置。那我们现在来逐个问题地讨论，首先物理内存多大是最容易回答的一个问题，然后操作系统估计使用多少内存呢？从经验上看，不会太多，通常应该在200M 以内（不包含大量进程PCB）。<br>接下来我们要探讨一个重要的问题，那就是关于文件系统和裸设备的问题，这往往容易被我们所忽略。操作系统对于文件系统，使用了大量的buffer 来缓存操作系统块。这样当数据库获取数据块的时候，虽然SGA 中没有命中，但却实际上可能是从操作系统的文件缓存中获取的。而假如数据库和操作系统支持异步IO，则实际上当数据库写进程DBWR写磁盘时，操作系统在文件缓存中标记该块为延迟写，等到真正地写入磁盘之后，操作系统才通知DBWR写磁盘完成。对于这部分文件缓存，所需要的内存可能比较大，作为保守的估计，我们应该考虑在 0.2——0.3 倍内存大小。但是如果我们使用的是裸设备，则不考虑这部分缓存的问题。这样的情况下SGA就有调大的机会。<br>关于数据库有多少并发连接，这实际上关系到PGA 的大小（MTS 下还有large_pool_size）。事实上这个问题应该说还跟OLTP 类型或者OLAP 类型相关。对于OLTP类型oracle 倾向于可使用MTS,对于OLAP 类型使用独立模式，同时OLAP 还可能涉及到大量的排序操作的查询，这些都影响到我们内存的使用。那么所有的问题综合起来，实际上主要反映在UGA的大小上。UGA主要包含以下部分内存设置</p>
<pre><code>SQL&gt; show parameters area_size

NAME                                TYPE    VALUE
------------------------------------              -------     --------
bitmap_merge_area_size                  integer    1048576
create_bitmap_area_size                  integer    8388608
hash_area_size                          integer     131072
sort_area_size                           integer     65536
SQL&gt;
</code></pre>
<p>在这部分内存中我们最关注的通常是sort_area_size，这是当查询需要排序的时候，数据库会话将使用这部分内存进行排序，当内存大小不足的时候，使用临时表空间进行磁盘排序。由于磁盘排序效率和内存排序效率相差好几个数量级，所以这个参数的设置很重要。<br>当出现大量排序时的磁盘I/O操作时，可以考虑增加sort_area_size的值。sort_area_size是Oracle用于一次排序所需的最大内存数，在排序结束但是结果列返回之前，Oracle会释放sort_area_size大小的内存，但是会保留 sort_area_retained_size大小的内存，知道最后一行结果列返回以后，才释放所有的内存。<br>会导致排序的语句有 SELECT DISTINCT , MINUS , INTERSECT , UNION 和 min()、max()、count() 操作；而不会导致排序的语句有 UPDATE , 带BETWEEN子句的SELECT 等等。<br>这四个参数都是针对会话进行设置的，是单个会话使用的内存的大小，而不是整个数据库使用的。偶尔会看见有人误解了这个参数以为是整个数据库使用的大小，这是极其严重的错误。假如设置了MTS，则UGA被分配在large_pool_size，也就是说放在了共享内存里面，不同进程（线程）之间可以共享这部分内存。在这个基础上，我们假设数据库存在并发执行server process 为100 个，根据上面我们4 个参数在oracle8.1.7 下的默认值，我们来计算独立模式下PGA 的大致大小。由于会话并不会经常使用create_bitmap_area_size、bitmap_merge_area_size，所以我们通常不对四个参数求和。在考虑到除这四个参数外会话所保存的变量、堆栈等信息，我们估计为 2M，则200 个进程最大可能使用200M 的PGA。</p>
<p>1.2.2  一个经验公式</p>
<p>现在，根据上面这些假定，我们来看SGA 实际能达到多少内存。在1G 的内存的服务器上，我们能分配给SGA 的内存大约为400—500M。若是2G 的内存，大约可以分到1G的内存给SGA，8G 的内存可以分到5G的内存给SGA。当然我们这里是以默认的排序部分内存sort_area_size=64k进行衡量的，假如我们需要调大该参数和 hash_area_size等参数，然后我们应该根据并发的进程的数量，来衡量考虑这个问题。</p>
<p>事实上，通常我们更习惯通过直观的公式化来表达这样的问题：<br>OS 使用内存+SGA+并发执行进程数*(sort_area_size+hash_ara_size+2M)&lt; 0.7*总内存</p>
<p>(公式是死的，系统是活的，实际应用的调整不必框公式，这不过是一个参考建议)</p>
<p>在我们的实际应用中，假如采用的是裸设备，我们可适当的增大SGA(如果需要的话)。由于目前几乎所有的操作系统都使用虚拟缓存，所以实际上如果就算SGA 设置的比较大也不会导致错误，而是可能出现频繁的内存页的换入与换出(page in/out)。在操作系统一级如果观察到这个现象，那么我们就需要调整内存的设置。</p>
<p>1.2.3  各个参数的设置<br>那么SGA中的各个参数具体应该按照什么样的原则来设置呢，下面进行讨论：<br>log_buffer<br>对于日志缓冲区的大小设置，通常我觉得没有过多的建议，因为参考LGWR写的触发条件之后，我们会发现通常超过3M意义不是很大。作为一个正式系统，可能考虑先设置这部分为log_buffer=1—3M 大小，然后针对具体情况再调整。<br>large_pool_size<br>对于大缓冲池的设置，假如不使用MTS，建议在20—30M 足够了。这部分主要用来保存并行查询时候的一些信息，还有就是RMAN 在备份的时候可能会使用到。如果设置了MTS，则由于UGA部分要移入这里，则需要具体根据session最大数量和 sort_ares_size 等相关会话内存参数的设置来综合考虑这部分大小的设置，一般可以考虑为session * (sort_area_size + 2M)。这里要提醒一点，不是必须使用MTS，我们都不主张使用MTS，尤其同时在线用户数小于500的情况下。。<br>java_pool_size<br>假如数据库没有使用JAVA，我们通常认为保留10—20M大小足够了。事实上可以更少，甚至最少只需要32k，但具体跟安装数据库的时候的组件相关(比如http server)。<br>shared_pool_size<br>这是迄今为止最具有争议的一部分内存设置。按照很多文档的描述，这部分内容应该几乎和数据缓冲区差不多大小。但实际上情况却不是这样的。首先我们要考究一个问题，那就是这部分内存的作用，是为了缓存已经被解析过的SQL，而使其能被重用，不再解析。这样做的原因是因为，对于一个新的SQL （shared_pool 里面不存在已经解析的可用的相同的SQL），数据库将执行硬解析，这是一个很消耗资源的过程。而若已经存在，则进行的仅仅是软分析（在共享池中寻找相同 SQL），这样消耗的资源大大减少。所以我们期望能多共享一些SQL，并且如果该参数设置不够大，经常会出现ora-04031错误，表示为了解析新的 SQL，没有可用的足够大的连续空闲空间，这样自然我们期望该参数能大一些。但是该参数的增大，却也有负面的影响，因为需要维护共享的结构，内存的增大也会使得SQL 的老化的代价更高，带来大量的管理的开销，所有这些可能会导致CPU 的严重问题。</p>
<p>在一个充分使用绑定变量的比较大的系统中，shared_pool_size的开销通常应该维持在300M 以内。除非系统使用了大量的存储过程、函数、包，比如oracleerp 这样的应用，可能会达到500M甚至更高。于是我们假定一个1G内存的系统，可能考虑设置该参数为100M，2G 的系统考虑设置为150M,8G 的系统可以考虑设置为200—300M。<br>对于一个没有充分使用或者没有使用绑定变量系统，这可能给我们带来一个严重的问题。所谓没有使用bind var 的SQL，我们称为Literal SQL。也就是比如这样的两句SQL我们认为是不同的SQL,需要进行2 次硬解析：<br>select * from EMP where name = ‘TOM’;<br>select * from EMP where name = ‘JERRY’;<br>假如把 ’TOM’ 和 ’JERRY’ 换做变量V，那就是使用了bind var，我们可以认为是同样的SQL 从而能很好地共享。共享SQL 本来就是shared_pool_size 这部分内存存在的本意，oracle的目的也在于此，而我们不使用bind var 就是违背了oracle 的初衷，这样将给我们的系统带来严重的问题。当然，如果通过在操作系统监控，没有发现严重的cpu问题，我们如果发现该共享池命中率不高可以适当的增加shred_pool_size。但是通常我们不主张这部分内存超过800M（特殊情况下可以更大）。<br>事实上，可能的话我们甚至要想办法避免软分析，这在不同的程序语言中实现方式有差异。我们也可能通过设置session_cached_cursors 参数来获得帮助（这将增大PGA）<br>关于使用绑定变量的话题，在下面的应用优化中继续讨论。</p>
<p>Data buffer<br>现在我们来谈数据缓冲区，在确定了SGA 的大小并分配完了前面部分的内存后，其余的，都分配给这部分内存。通常，在允许的情况下，我们都尝试使得这部分内存更大。这部分内存的作用主要是缓存 DB BLOCK，减少甚至避免从磁盘上获取数据，在8i中通常是由db_block_buffers*db_block_size 来决定大小的。如果我们设置了buffer_pool_keep 和buffer_pool_recycle，则应该加上后面这两部分内存的大小。</p>
<p>可以看出，设置SGA时基本上应该掌握的原则是：<br>  data buffer 一般可以尽可能的大<br>  shared_pool_size 应该适度<br>  log buffer 在 1MB 以内就可以了</p>
<p>假定oracle是 32 bit ,服务器RAM大于2G ，注意你的PGA的情况，,则建议<br>shared_pool_size + data buffer +large_pool_size + java_pool_size &lt; 1.6G</p>
<p>再具体化，如果512M RAM<br>建议 shared_pool_size = 50M, data buffer = 200M</p>
<p>如果1G RAM<br>shared_pool_size = 100M , data buffer = 500M</p>
<p>如果2G RAM<br>shared_pool_size = 150M ,data buffer = 1.2G</p>
<p>物理内存再大已经跟参数没有关系了</p>
<p>假定64 bit ORACLE<br>内存4G<br>shared_pool_size = 200M , data buffer = 2.5G</p>
<p>内存8G<br>shared_pool_size = 300M , data buffer = 5G</p>
<p>内存 12G<br>shared_pool_size = 300M—–800M , data buffer = 8G</p>
<p>1.3  32bit 与 64bit 对SGA的影响<br>为什么在上面SGA大小设置的经验规则中要分 32bit Oracle 和 64bit Oracle 呢，是因为这关系到SGA大小的上限问题。在32bit的数据库下，通常oracle只能使用不超过1.7G的内存，即使我们拥有12G的内存，但是我们却只能使用1.7G，这是一个莫大的遗憾。假如我们安装64bit的数据库,我们就可以使用很大的内存，几乎不可能达到上限。但是64bit的数据库必须安装在64bit 的操作系统上，可惜目前windows上只能安装32bit的数据库，我们通过下面的方式可以查看数据库是32bit 还是 64bit ：</p>
<pre><code>SQL&gt; select * from v$version;
BANNER
----------------------------------------------------------------
Oracle8i Enterprise Edition Release 8.1.7.0.0 - Production
PL/SQL Release 8.1.7.0.0 - Production
CORE 8.1.7.0.0 Production
TNS for 32-bit Windows: Version 8.1.7.0.0 - Production
NLSRTL Version 3.4.1.0.0 – Production
</code></pre>
<p>在UNIX平台下的显示有所不同，明显可以看出是 64bit Oracle ，比如在HP-UX平台上：</p>
<pre><code>SQL&gt; select * from v$version;

BANNER
----------------------------------------------------------------
Oracle8i Enterprise Edition Release 8.1.7.4.0 - 64bit Production
PL/SQL Release 8.1.7.4.0 - Production
CORE    8.1.7.0.0       Production
TNS for HPUX: Version 8.1.7.4.0 - Production
NLSRTL Version 3.4.1.0.0 – Production
</code></pre>
<p>32bit的oracle无论跑在32bit或者64bit的平台都有SGA的限制的，而对于32bit的平台只能跑32bit的oracle，但是在特定的操作系统下，可能提供了一定的手段，使得我们可以使用超过1.7G 的内存，达到2G 以上甚至更多。由于我们现在一般都使用64bit Oracle，因此关于如何在32bit平台上扩展SGA大小的问题不再赘述。</p>
<p>1.4  9i中相关参数的变化<br>oracle的版本的更新，总是伴随着参数的变化，并且越来越趋向于使得参数的设置更简单，因为复杂的参数设置使得DBA们经常焦头烂额。关于内存这部分的变化，我们可以考察下面的参数。事实上在9i中数据库本身可以给出一组适合当前运行系统的SGA相关部分的参数调整值（参考V$ DB_CACHE_ADVICE、V$SHARED_POOL_ADVICE），关于PGA也有相关视图V$PGA_TARGET_ADVICE 等。</p>
<p>Data buffer<br>9i 中保留了8i中的参数，如设置了新的参数，则忽略旧的参数。9i中用db_cache_size来取代db_block_buffers ， 用db_keep_cache_size 取代buffer_pool_keep,用db_recycle_cache_size 取代buffer_pool_recycle；这里要注意9i 中设置的是实际的缓存大小而不再是块的数量。另外9i新增加了db_nk_cache_size，这是为了支持在同一个数据库中使用不同的块大小而设置的。对于不同的表空间，可以定义不同的数据块的大小，而缓冲区的定义则依靠该参数的支持。其中n 可以为2、4、6、8、16 等不同的值。在这里顺便提及的一个参数就是db_block_lru_latches，该参数在9i中已经成为了保留参数，不推荐手工设置。</p>
<p>PGA<br>在9i 里面这部分也有了很大的变化。在独立模式下，9i已经不再主张使用原来的UGA相关的参数设置，而代之以新的参数。假如workarea_size_policy=AUTO（缺省），则所有的会话的UGA 共用一大块内存，该内存由 pga_aggregate_target 设置。在我们根据前面介绍的方法评估了所有进程可能使用的最大PGA 内存之后，我们可以通过在初始化参数中设置这个参数，从而不再关心其他”*_area_size” 参数。</p>
<p>SGA_MAX_SIZE<br>在9i中若设置了SGA_MAX_SIZE，则在总和小于等于这个值内，可以动态的调整数据缓冲区和共享池的大小</p>
<pre><code>SQL&gt; show parameters sga_max_size
NAME      TYPE            VALUE
---------------- -------------------- ------- -------------
sga_max_size  unknown        193752940
SQL&gt;
SQL&gt; alter system set db_cache_size = 30000000;
System altered.
SQL&gt; alter system set shared_pool_size = 20480000;
System altered.
</code></pre>
<p>1.5  lock_sga = true 的问题<br>由于几乎所有的操作系统都支持虚拟内存，所以即使我们使用的内存小于物理内存，也不能避免操作系统将SGA 换到虚拟内存（SWAP）。所以我们可以尝试使得SGA 锁定在物理内存中不被换到虚拟内存中，这样减少页面的换入和换出，从而提高性能。但在这里遗憾的是，windows 是无法避免这种情况的。下面我们来参考在不同的几个系统下怎么实现lock_sga</p>
<pre><code>AIX 5L（AIX 4.3.3 以上）
logon aix as root
cd /usr/samples/kernel
./vmtune (信息如下) v_pingshm已经是1
./vmtune -S 1
</code></pre>
<p>然后oracle用户修改initSID.ora 中 lock_sga = true<br>重新启动数据库</p>
<pre><code>HP UNIX
Root身份登陆
Create the file &quot;/etc/privgroup&quot;: vi /etc/privgroup
Add line &quot;dba MLOCK&quot; to file
As root, run the command &quot;/etc/setprivgrp -f /etc/privgroup&quot;:
$/etc/setprivgrp -f /etc/privgroup
oracle用户修改initSID.ora中lock_sga=true
</code></pre>
<p>重新启动数据库</p>
<p>SOLARIS (solaris2.6以上)<br>8i版本以上数据库默认使用隐藏参数 use_ism = true ，自动锁定SGA于内存中,不用设置lock_sga, 如果设置 lock_sga =true 使用非 root 用户启动数据库将返回错误。</p>
<p>WINDOWS<br>不能设置lock_sga=true,可以通过设置pre_page_sga=true,使得数据库启动的时候就把所有内存页装载，这样可能起到一定的作用。</p>
<ol start="2">
<li> 应用优化<br>下面我们从技术的角度入手，来探讨数据库优化方面的问题。通常作为优化Oracle系统的人，或者是DBA，其实很多时候对应用并不很了解甚至可以说是完全不了解，更不要说对应用程序代码的了解。事实上呢，一个系统运行的快或者慢相信大家都明白，第一重要的是数据库的设计，然后是应用的设计， SQL语句的编写，最后才是数据库参数的调整和硬件、网络的问题，等等。所以在我们不了解一个系统的时候来优化数据库应用不是一个轻松的容易的事情。那么我们第一步应该怎么做呢？<br>通常有两类方法：<br>其中一个方法就是我们常用的，使用statspack来进行诊断系统的瓶颈所在。在statspack中oracle给出了几乎涵盖oracle大部分重要内容的信息。<br>另外一种方式，就是trace session。假如某个session运行很慢或者某个用户的某个查询很慢，那么这个时候我们可以通过trace session的方式来诊断到底是慢在哪里，看究竟执行计划是怎样的，然后在user_dump_dest下根据该session的进程号或者线程号可以找到一个产生的trace文件。通过使用tkprof格式化文件之后我们就可以看见很多的统计信息，这里包括了执行计划、parse/fetch等步骤消耗cpu的时间。通常我们是观察query模式下的consistent gets来首先看sql是否使用了索引，然后看执行计划是不是正常，是不是有调整的余地。当然如果您没有实际做过的话，这些内容说起来很抽象。这是在不了解应用和程序下针对特定session的诊断和调整过程。<br>trace session的方式是一种自下而上的方法，从sql入手；而statspack是自顶向下的方法，也就是从宏观上先诊断数据库的瓶颈在哪里，然后从瓶颈入手来做调整，这个习惯上又可以称为通过等待事件（wait event）入手的方法。</li>
</ol>
<p>2.1  使用statspack<br>statspack是一个性能诊断工具，首先发布于Oracle8.1.6版本，在8.1.7版本中功能得到加强。Statspack除了查找实例中的性能问题外，还可以查找应用程序中高负荷的SQL语句，很容易确定Oracle 数据库的瓶颈所在，并且记录数据库性能状态。<br>在数据库中Statspack 的脚本位于$ORACLE_HOME/RDBMS/ADMIN 目录下，对于ORACLE8.1.6,是一组以stat 开头的文件；对于ORACLE8.1.7,是一组以sp 开头的文件。<br>在Statspack 发布之前，我们通常能够使用诊断数据库的工具是两个脚本UTLBSTAT.SQL和UTLESTAT.SQL，BSTAT/ESTAT 是一个非常简单的性能诊断工具。UTLBSTAT 获得开始时很多V$视图的快照，UTLESTAT 通过先前的快照和当前视图生成一个报表。<br>该报表实际上相当于statspack 中的两个采样点。<br>Statspack 通过连续的采样，能够给我们提供至关重要的趋势分析数据。这是一个巨大的进步。能够使用Statspack 的环境我们就尽量不要使用BSTAT/ESTAT 的方式来诊断数据库问题。</p>
<p>2.1.1  安装statapack<br>§ 步骤一：<br>为了能够顺利安装和运行Statspack ，首先需要设置以下两个系统参数：</p>
<ol>
<li><p>job_queue_processes<br>为了能够建立自动任务，执行数据收集，该参数需要大于0。你可以在初试化参数文件中修改该参数(使该参数在重起后以然有效)。<br>该参数可以在系统级动态修改(重起后失效)。</p>
<p> SQL&gt; alter system setjob_queue_processes = 6;<br> System altered</p>
</li>
</ol>
<p>在Oracle9i 当中，可以指定范围，如 both,这样该修改在当前及之后保持有效(仅当你使用spfile 时，如果在9i 中仍然使用pfile，那么更改方法同8i 相同):</p>
<pre><code>SQL&gt; alter system setjob_queue_processes = 6 scope=both;
System altered
</code></pre>
<ol start="2">
<li><p>timed_statistics<br>收集操作系统的计时信息，这些信息可被用来显示时间等统计信息、优化数据库和 SQL 语句。要防止因从操作系统请求时间而引起的开销，请将该值设置为False。<br>使用statspack 收集统计信息时建议将该值设置为 TRUE，否则收集的统计信息大约只能起到10%的作用，将timed_statistics 设置为True 所带来的性能影响与好处相比是微不足道的。<br>该参数使收集的时间信息存储在在V$SESSTATS 和V$SYSSTATS 等动态性能视图中。<br>timed_statistics 参数也可以在实例级进行更改</p>
<p> SQL&gt; alter system settimed_statistics = true;<br> System altered</p>
</li>
</ol>
<p>如果你担心一直启用timed_statistics 对于性能的影响，你可以在使用statspack 之前在system 更改，采样过后把该参数动态修改成false。</p>
<p>§ 步骤二：<br>需要单独为statspack创建一个存储数据的表空间，如果采样间隔较短，周期较长，打算长期使用，那么可能需要一个大一点的表空间，如果每个半个小时采样一次，连续采样一周，数据量是很大的。下面的例子中创建了一个500M 的测试表空间。<br>注意: 这里创建的表空间不能太小，如果太小的话创建对象会失败，建议至少建立100M 表空间。</p>
<pre><code>SQL&gt; create tablespace perfstat
2 datafile &#39;/oracle/oradata/oradata/res/perfstat.dbf&#39;
3 size 500M;
Tablespace created。
</code></pre>
<p>§ 步骤三：<br>在 sqlplus 中用internal 身份登陆，或者拥有SYSDBA(connect / as sysdba)权限的用户登陆。<br>注: 在Oracle9i 中，不存在internal 用户，可以使用sys 用户以sysdba 身份连接。<br>先转到$ORACLE_HOME/RDBMS/ADMIN 目录，检查安装脚本是否存在，同时我们执行脚本也可以方便些。</p>
<pre><code>$ cd $ORACLE_HOME/rdbms/admin
$ ls -l sp*.sql
-rw-r--r--   1 oracle  other       1774 Feb 18  2000 spauto.sql
-rw-r--r--   1 oracle   other     62545 Jun 15  2000 spcpkg.sql
-rw-r--r--   1 oracle  other        877 Feb 18  2000spcreate.sql
-rw-r--r--   1 oracle   other     31193 Jun 15  2000 spctab.sql
-rw-r--r--   1 oracle  other       6414 Jun 15  2000 spcusr.sql
-rw-r--r--   1 oracle  other        758 Jun 15  2000spdrop.sql
-rw-r--r--   1 oracle  other       3615 Jun 15  2000 spdtab.sql
-rw-r--r--   1 oracle  other       1274 Jun 15  2000 spdusr.sql
-rw-r--r--   1 oracle  other       6760 Jun 15  2000 sppurge.sql
-rw-r--r--   1 oracle   other     71034 Jul 12  2000 spreport.sql
-rw-r--r--   1 oracle  other       2191 Jun 15  2000 sptrunc.sql
-rw-r--r--   1 oracle   other     30133 Jun 15  2000 spup816.sql
$
</code></pre>
<p>接下来我们就可以开始安装Statspack 了。在Oracle8.1.6 版本中运行statscre.sql; 在Oracle8.1.7 版本中运行spcreate.sql。<br>这期间会提示你输入缺省表空间和临时表空间的位置,输入我们为 perfstat 用户创建的表空间和你的临时表空间。安装脚本会自动创建perfstat 用户。</p>
<pre><code>$ sqlplus

SQL*Plus: Release 8.1.7.0.0 - Productionon Sat Jul 26 16:27:31 2003

(c) Copyright 2000 OracleCorporation.  All rights reserved.

Enter user-name: internal

Connected to:
Oracle8i Enterprise Edition Release 8.1.7.0.0 - Production
With the Partitioning option
JServer Release 8.1.7.0.0 - Production

SQL&gt;
SQL&gt; @spcreate
... Installing Required Packages

Package created.

Grant succeeded.

View created.

Package body created.

Package created.

Synonym dropped.

Synonym created.
……

Specify PERFSTAT user&#39;sdefault   tablespace
Enter value for default_tablespace: perfstat
Using perfstat for the default tablespace

User altered.

User altered.

Specify PERFSTAT user&#39;s temporarytablespace
Enter value for temporary_tablespace: temp
Using temp for the temporary tablespace

User altered.

NOTE:
SPCUSR complete. Please check spcusr.lis for any errors.

……
</code></pre>
<p>如果安装成功，你可以接着看到如下的输出信息：</p>
<pre><code>….
Creating Package STATSPACK...

Package created.

No errors.
Creating Package Body STATSPACK...

Package body created.

No errors.

NOTE:
SPCPKG complete. Please check spcpkg.lis for any errors.
</code></pre>
<p>可以查看.lis 文件查看安装时的错误信息。</p>
<p>§ 步骤四：<br>如果安装过程中出现错误，那么可以运行spdrop.sql 脚本来删除这些安装脚本建立的对象。然后重新运行spcreate.sql来创建这些对象。</p>
<pre><code>SQL&gt; @spdrop
Dropping old versions (if any)

Synonym dropped.

Sequence dropped.

Synonym dropped.

Table dropped.

Synonym dropped.

View dropped.
……
NOTE:
SPDUSR complete. Please check spdusr.lis for any errors.
</code></pre>
<p>（以上的安装过程描述是在 HP 11.11 + Oracle8.1.7 平台上得到的）</p>
<p>2.1.2  测试statspack<br>运行statspack.snap 可以产生系统快照，运行两次，然后执行spreport.sql就可以生成一个基于两个时间点的报告。<br>如果一切正常，说明安装成功。</p>
<pre><code>SQL&gt;execute statspack.snap
PL/SQL procedure successfully completed.
SQL&gt;execute statspack.snap
PL/SQL procedure successfully completed.
SQL&gt;@spreport.sql
</code></pre>
<p>可是有可能你会得到以下错误：</p>
<pre><code>SQL&gt; exec statspack.snap;
BEGIN statspack.snap; END;
*
ERROR at line 1:
ORA-01401: inserted value too large for column
ORA-06512: at &quot;PERFSTAT.STATSPACK&quot;, line 978
ORA-06512: at &quot;PERFSTAT.STATSPACK&quot;, line 1612
ORA-06512: at &quot;PERFSTAT.STATSPACK&quot;, line 71
ORA-06512: at line 1
</code></pre>
<p>这是Oracle 的一个Bug，Bug 号1940915。<br>该Bug 自8.1.7.3 后修正。<br>这个问题只会出现在多位的字符集, 需要修改spcpkg.sql 脚本，$ORACLE_HOME/rdbms/admin/spcpkg.sql，将”substr” 修改为”substrb”，然后重新运行该脚本。<br>该脚本错误部分：<br>select l_snap_id<br>, p_dbid<br>, p_instance_number<br>, substr(sql_text,1,31)<br>．．．．．．．．．．．<br>substr 会将多位的字符, 当作一个byte.substrb 则会当作多个byte。在收集数据时， statpack 会将 top10 的 sql 前 31 个字节 存入数据表中,若在SQL 的前31 个字有中文，就会出现此错误。<br>注意：运行 spcpkg.sql 也需要以 internal 用户登录 sqlplus</p>
<p>2.1.3  生成statspack报告<br>调用spreport.sql 可以生成分析报告：<br>当调用spreprot.sql 时，系统首先会查询快照列表，然后要求你选择生成报告的开始快照ID(begin_snap)和结束快照ID(end_snap),生成一个报告.<br>为了生成一个report,我们至少需要两次采样:</p>
<pre><code>SQL&gt; @spreport 

   DB Id    DBName      Inst Num Instance
-----------   ------------      -------- ------------
  2749170756RES             1      res

Completed Snapshots

                          Snap                   Snap
Instance     DBName         Id   SnapStarted    Level Comment
------------ ------------ ----- ----------------- ----- ----------------------
res         RES             1 26 Jul 2003 16:36     5
                             2 26 Jul 2003 16:37     5
                             3 26 Jul 2003 17:03     5

Specify the Begin and End Snapshot Ids
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Enter value for begin_snap:2</span><br><span class="line">Begin Snapshot Id specified: 2</span><br><span class="line"></span><br><span class="line">Enter value for end_snap: 3</span><br><span class="line">End   Snapshot Id specified: 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Specify the Report Name</span><br></pre></td></tr></table></figure>
The default report file name is sp_2_3.  To use this name,
press to continue, otherwise enter an alternative.
Enter value for report_name: rep0726.txt 

 ……

 Endof Report
</code></pre>
<p>在运行 spreport.sql 生成 statspack 报告的过程中，会有三个地方提示用户输入：<br>1、 开始快照ID；<br>2、 结束快照ID；<br>3、 输出报告文件的文件名，缺省的文件名是sp__<br>上面输入的开始快照ID是2，开始快照ID是3，输出报告文件的文件名是rep0726.txt<br>成功运行一次 statspack.snap 就会产生一个 snapshot ，在生成 statspack 报告的时候就可以看到这个 snap id 和 snap 运行的时间。运行 statspack.snap ，就是上面所说的采样，statspack 报告是分析两个采样点之间各种情况。</p>
<p>2.1.4  删除历史快照数据<br>前面讲过，成功运行一次 statspack.snap 就会产生一个 snapshot ，这个 snapshot 的基本信息是存放在 PERFSTAT.stats$snapshot 表中的，生成 statspack报告时会查询该表的数据，供用户选择准备分析的snapshot 。如果运行 statspack.snap 次数多了以后，该表的数据也会增加，历史数据会影响正常运行的效果，因此需要定时清理一下历史快照数据。<br>删除stats$snapshot 数据表中的相应数据，其他表中的数据会相应的级连删除：</p>
<pre><code>SQL&gt; select max(snap_id) fromstats$snapshot;
MAX(SNAP_ID)
------------
166

SQL&gt; delete from stats$snapshot wheresnap_id &lt; = 166;
143 rows deleted
</code></pre>
<p>你可以更改snap_id 的范围以保留你需要的数据。<br>在以上删除过程中，你可以看到所有相关的表都被锁定。</p>
<pre><code>SQL&gt; select a.object_id,a.oracle_username ,b.object_name
from v$locked_object a,dba_objects b
where a.object_id = b.object_id
/
OBJECT_ID ORACLE_USERNAME OBJECT_NAME
---------------------------------------------------------------------------------------------------------------------
156 PERFSTAT SNAP$
39700 PERFSTAT STATS$LIBRARYCACHE
39706 PERFSTAT STATS$ROLLSTAT
39712 PERFSTAT STATS$SGA
39754 PERFSTAT STATS$PARAMETER
39745 PERFSTAT STATS$SQL_STATISTICS
39739 PERFSTAT STATS$SQL_SUMMARY
39736 PERFSTAT STATS$ENQUEUESTAT
39733 PERFSTAT STATS$WAITSTAT
39730 PERFSTAT STATS$BG_EVENT_SUMMARY
39724 PERFSTAT STATS$SYSTEM_EVENT
39718 PERFSTAT STATS$SYSSTAT
39715 PERFSTAT STATS$SGASTAT
39709 PERFSTAT STATS$ROWCACHE_SUMMARY
39703 PERFSTAT STATS$BUFFER_POOL_STATISTICS
39697 PERFSTAT STATS$LATCH_MISSES_SUMMARY
39679 PERFSTAT STATS$SNAPSHOT
39682 PERFSTAT STATS$FILESTATXS
39688 PERFSTAT STATS$LATCH
174 PERFSTAT JOB$
20 rows selected
</code></pre>
<p>Oracle 还提供了系统脚本用于Truncate这些统计信息表，这个脚本名字是: sptrunc.sql (8i、9i 都相同)<br>该脚本主要内容如下，里面看到的就是statspack 相关的所有系统表：</p>
<pre><code>truncate table STATS$FILESTATXS;
truncate table STATS$LATCH;
truncate table STATS$LATCH_CHILDREN;
truncate table STATS$LATCH_MISSES_SUMMARY;
truncate table STATS$LATCH_PARENT;
truncate table STATS$LIBRARYCACHE;
truncate table STATS$BUFFER_POOL_STATISTICS;
truncate table STATS$ROLLSTAT;
truncate table STATS$ROWCACHE_SUMMARY;
truncate table STATS$SGA;
truncate table STATS$SGASTAT;
truncate table STATS$SYSSTAT;
truncate table STATS$SESSTAT;
truncate table STATS$SYSTEM_EVENT;
truncate table STATS$SESSION_EVENT;
truncate table STATS$BG_EVENT_SUMMARY;
truncate table STATS$WAITSTAT;
truncate table STATS$ENQUEUESTAT;
truncate table STATS$SQL_SUMMARY;
truncate table STATS$SQL_STATISTICS;
truncate table STATS$SQLTEXT;
truncate table STATS$PARAMETER;
delete from STATS$SNAPSHOT;
delete from STATS$DATABASE_INSTANCE;
commit;
</code></pre>
<p>2.1.5  一些重要脚本<br>1．通过导出保存及共享数据<br>在诊断系统问题时，可能需要向专业人士提供原始数据，这时我们可以导出Statspack 表数据，<br>其中我们可能用到：spuexp.par<br>其内容主要为：<br>file=spuexp.dmp log=spuexp.log compress=y grants=y indexes=y rows=yconstraints=y owner=PERFSTAT consistent=y<br>我们可以导出如下：<br>exp userid=perfstat/my_perfstat_password parfile=spuexp.par</p>
<p>2．删除数据<br>spdrop.sql 在执行时主要调用两个脚本: spdtab.sql 、spdusr.sql<br>前者删除表及同义词等数据，后者删除用户</p>
<p>3．Oracle92中新增加的脚本<br>1） 用于升级statspack 对象的脚本,这些脚本需要以具有SYSDBA 权限的用户运行, 升级前请先<br>备份存在的Schema 数据:<br>spup90.sql: 用于升级9.0 版本的模式至9.2 版本。<br>spup817.sql: 如果从Statspack 8.1.7 升级,需要运行这个脚本<br>spup816.sql: 从Statspack 8.1.6 升级,需要运行这个脚本，然后运行spup817.sql<br>2） sprepsql.sql 用于根据给定的SQL Hash 值生成SQL 报告</p>
<p>2.1.6  调整statspack的收集门限<br>Statspack 有两种类型的收集选项：</p>
<p>1．级别（level）：控制收集数据的类型<br>Statspack 共有三种快照级别，默认值是5<br>a. level 0: 一般性能统计。包括等待事件、系统事件、系统统计、回滚段统计、行缓存、SGA、会话、锁、缓冲池统计等等。<br>b. level 5: 增加SQL 语句。除了包括level0 的所有内容，还包括SQL 语句的收集，收集结果记录在stats$sql_summary 中。<br>c. level 10: 增加子锁存统计。包括level5 的所有内容。并且还会将附加的子锁存存入stats$lathc_children中。在使用这个级别时需要慎重，建议在Oracle support 的指导下进行。<br>可以通过statspack 包修改缺省的级别设置<br>SQL&gt;executestatspack.snap(i_snap_level=&gt;0,i_modify_parameter=&gt;’true’);<br>通过这样的设置，以后的收集级别都将是0 级。<br>如果你只是想本次改变收集级别，可以忽略i_modify_parameter 参数。<br>SQL&gt;execute statspack.snap(i_snap_level=&gt;10);</p>
<p>2．快照门限：设置收集的数据的阈值。<br>快照门限只应用于stats$sql_summary 表中获取的SQL 语句。<br>因为每一个快照都会收集很多数据，每一行都代表获取快照时数据库中的一个SQL 语句，所以stats$sql_summary 很快就会成为Statspack 中最大的表。<br>门限存储在stats$statspack_parameter 表中。让我们了结一下各种门限：<br>a. executions_th 这是SQL 语句执行的数量(默认值是100)<br>b. disk_reads_tn 这是SQL 语句执行的磁盘读入数量（默认值是1000）<br>c. parse_calls_th 这是SQL 语句执行的解析调用的数量（默认值是1000）<br>d. buffer_gets_th 这是SQL 语句执行的缓冲区获取的数量（默认值是10000）<br>任何一个门限值超过以上参数就会产生一条记录。<br>通过调用statspack.modify_statspack_parameter 函数我们可以改变门限的默认值。<br>例如：<br>SQL&gt;executestatspack.modify_statspack_parameter(i_buffer_gets_th=&gt;100000,i_disk_reads_th=&gt;100000;</p>
<p>2.2  对statspack报告的分析<br>从上面的描述可以看出，产生一个statspack报告是比较简单的，但是如何读懂statspack报告却不是那么容易，需要对Oracle的体系架构、内存结构、等待事件以及应用系统有充分的了解，加上不断的实践，才能基本读懂statspack报告并且从报告中找到调整优化Oracle的途径。<br>下面接合一个实际的statspack报告，大致分析一下。</p>
<p>2.2.1  基本信息分析</p>
<pre><code>DB Name         DB Id   Instance     Inst Num Release     OPSHost
------------ ----------- --------------------          --------------      ---------  ---
RES           2749170756res                1  8.1.7.0.0   NO  res

               Snap Id     Snap Time     Sessions
               ------- ------------------ --------
 Begin Snap:          226-Jul-03 16:37:08       38
   End Snap:          326-Jul-03 17:03:23       38
   Elapsed:                 26.25 (mins)
</code></pre>
<p>Statspack报告首先描述了数据库的基本情况，比如数据库名、实例名、实例个数、oracle版本号等等；然后是该报告的开始快照和结束快照的信息，包括 snapid , snap time 等等；最后是该报告经过的时间跨度，单位是分钟(mins)。</p>
<p>Cache Sizes</p>
<p>~~~~~~~~~~~<br>db_block_buffers:     61440         log_buffer:     163840<br>db_block_size:        8192     shared_pool_size:   52428800</p>
<p>然后描述了Oracle内存结构中几个重要的参数。</p>
<p>2.2.2  内存信息分析</p>
<pre><code>Load Profile
~~~~~~~~~~~~                      Per Second       Per Transaction
                                  ---------------       ---------------
             Redosize:             4,834.87            11,116.67
          Logicalreads:               405.53               932.43
          Blockchanges:                60.03               138.02
          Physicalreads:               138.63               318.75
          Physicalwrites:                54.27               124.79
          Usercalls:                    62.69               144.13
         Parses:                       19.14                44.00
          Hardparses:                   2.26                 5.20
                 Sorts:                 1.83                 4.20
                Logons:                 0.21                 0.47
              Executes:                21.10                48.50
           Transactions:                 0.43

  % Blocks changed perRead:   14.80    Recursive Call %:   34.45
 Rollback per transaction %:   0.00       Rows per Sort:   20.57
</code></pre>
<p>Redo size: 是日志的生成量，分为每秒和每事务所产生的，通常在很繁忙的系统中日志生成量可能达到上百k，甚至几百k；</p>
<p>Logical reads: 逻辑读实际上就是logical IO=buffer gets表示的含义，我们可以这样认为，block在内存中，我们每一次读一块内存，就相当于一次逻辑读；</p>
<p>Parses 和 Hardparses:  Parse 和 hard parse通常是很容易出问题的部分，80%的系统的慢都是由于这个原因所导致的。<br>所谓parse分soft parse 和hard parse，soft parse是当一条sql传进来后，需要在shared pool中找是否有相同的sql，如果找到了，那就是soft parse，如果没有找着，那就开始hard parse，实际上hard parse主要是检查该sql所涉及到的所有的对象是否有效以及权限等关系，hardparse之后才根据rule/cost模式生成执行计划，再执行sql。<br>而hard parse的根源，基本都是由于不使用bind var所导致的，不使用bind var违背了oracle的shared pool的设计的原则，违背了这个设计用来共享的思想，这样导致shared_pool_size里面命中率下降。因此不使用bind var，将导致cpu使用率的问题，极有使得性能急剧下降。<br>还有就是为了维护internal structure，需要使用latch，latch是一种Oracle低级结构,用于保护内存资源，是一种内部生命周期很短的lock，大量使用latch将消耗大量的cpu资源。</p>
<p>Sorts: 表示排序的数量；</p>
<p>Executes: 表示执行次数；</p>
<p>Transactions: 表示事务数量；</p>
<p>Rollback per transaction %: 表示数据库中事务的回退率。如果不是因为业务本身的原因，通常应该小于10%为好，回退是一个很消耗资源的操作。</p>
<pre><code>Instance Efficiency Percentages (Target 100%)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           Buffer Nowait%:  100.00       Redo NoWait %:  99.98
           Buffer Hit   %:   65.82    In-memory Sort%:   99.65
           LibraryHit   %:   91.32       Soft Parse %:   88.18
         Execute to Parse%:    9.28         LatchHit %:   99.99
Parse CPU to Parse Elapsd %:   94.61     %Non-Parse CPU:   99.90
</code></pre>
<p>Buffer Hit %: 数据缓冲区命中率，通常应该大于90%；</p>
<p>Library Hit %: libaray cache的命中率，通常应该大于98%；</p>
<p>In-memory Sort %: 排序在内存的比例，如果这个比例过小，可以考虑增大sort_area_size，使得排序在内存中进行而不是在temp表空间中进行；</p>
<p>Soft Parse %: 软解析的百分比，这个百分比也应该很大才好，因为我们要尽量减少hard parse。 soft parse 百分比=soft/(soft+hard)；</p>
<p>Execute to Parse %: 这个数字也应该是越大越好，接近100%最好。有些报告中这个值是负的，看上去很奇怪。事实上这表示一个问题，sql如果被age out的话就可能出现这种情况，也就是sql老化，或执行alter system flush shared_pool等。</p>
<pre><code>Shared Pool Statistics         Begin   End
                            ------   ------
         Memory Usage%:    90.63   87.19
   % SQL with executions&gt;1:   71.53   75.39
 % Memory for SQL w/exec&gt;1:  59.45   65.17
</code></pre>
<p>% SQL with executions&gt;1: 这个表示SQL被执行次数多于一次的比率，也应该大为好，小则表示很多sql只被执行了一次，说明没有使用bind var；</p>
<p>2.2.3  等待事件分析<br>接下来，statspack报告中描述的是等待事件（Wait Events），这是Oracle中比较复杂难懂的概念。<br>Oracle 的等待事件是衡量Oracle 运行状况的重要依据及指标。<br>等待事件的概念是在Oracle7.0.1.2 中引入的，大致有100 个等待事件。在Oracle 8.0 中这个数目增加到了大约150 个，在Oracle8i 中大约有200 个事件,在Oracle9i 中大约有360 个等待事件。<br>主要有两种类别的等待事件，即空闲（idle）等待事件和非空闲（non-idle）等待事件。<br>空闲事件指Oracle 正等待某种工作,在诊断和优化数据库的时候,我们不用过多注意这部分事件。<br>常见的空闲事件有:</p>
<pre><code>? dispatcher timer
? lock element cleanup
? Null event
? parallel query dequeue wait
? parallel query idle wait - Slaves
? pipe get
? PL/SQL lock timer
? pmon timer- pmon
? rdbms ipc message
? slave wait
? smon timer
? SQL*Net break/reset to client
? SQL*Net message from client
? SQL*Net message to client
? SQL*Net more data to client
? virtual circuit status
? client message
</code></pre>
<p>非空闲等待事件专门针对Oracle 的活动,指数据库任务或应用运行过程中发生的等待，这些等待事件是我们在调整数据库的时候应该关注与研究的。<br>一些常见的非空闲等待事件有:</p>
<pre><code>? db file scattered read
? db file sequential read
? buffer busy waits
? free buffer waits
? enqueue
? latch free
? log file parallel write
? log file sync
</code></pre>
<p>下面接合statspack中的一些等待事件进行讲述。</p>
<pre><code>Top 5 Wait Events
~~~~~~~~~~~~~~~~~                             Wait     % Total
Event                                   Waits  Time (cs)   Wt Time
--------------------------------------------          ------------ ------------    -------
db file scatteredread                     26,877       12,850   52.94
db file parallelwrite                        472        3,674   15.13
log file parallel write                        975        1,560    6.43
direct pathwrite                          1,571        1,543    6.36
control file parallelwrite                    652        1,290    5.31
         -------------------------------------------------------------
</code></pre>
<p>db file scattered read: DB文件分散读取。这个等待事件很常见，经常在top5中出现，这表示，一次从磁盘读数据进来的时候读了多于一个block的数据，而这些数据又被分散的放在不连续的内存块中，因为一次读进来的是多于一个block的。<br>通常来说我们可以认为是全表扫描类型的读，因为根据索引读表数据的话一次只读一个block，如果这个数字过大，就表明该表找不到索引，或者只能找到有限的索引，可能是全表扫描过多，需要检查sql是否合理的利用了索引，或者是否需要建立合理的索引。<br>当全表扫描被限制在内存时，它们很少会进入连续的缓冲区内，而是分散于整个缓冲存储器中。尽管在特定条件下执行全表扫描可能比索引扫描更有效，但如果出现这种等待时，最好检查一下这些全表扫描是否必要,是否可以通过建立合适的索引来减少对于大表全表扫描所产生的大规模数据读取。<br>对于经常使用的小表，应该尽量把他们pin 在内存中，避免不必要的老化清除及重复读取。</p>
<p>db file sequential read: DB文件连续读取。通常显示单个块的读取(通常指索引读取)，表示的是读进磁盘的block被放在连续的内存块中。<br>事实上大部分基本代表着单个block的读入，可以说象征着 IO 或者说通过索引读入的比较多。因为一次IO若读进多个的block，放入连续的内存块的几率是很小的，分布在不同block的大量记录被读入就会遇到此事件。因为根据索引读数据的话，假设100条记录，根据索引，不算索引本身的读，而根据索引每个值去读一下表数据，理论上最多可能产生100 buffer gets，而如果是full table scan，则100条数据完全可能在一个block里面，则几乎一次就读过这个block了，就会产生这么大的差异。<br>这种等待的数目很多时，可能显示表的连接顺序不佳，或者不加选择地进行索引。<br>对于高级事务处理（high-transaction）、调整良好（welltuned）的系统，这一数值很大是很正常的，但在某些情况下，它可能暗示着系统中存在问题。<br>你应当将这一等待统计量与Statspack 报告中的已知问题（如效率较低的SQL）联系起来。检查索引扫描，以保证每个扫描都是必要的，并检查多表连接的连接顺序。<br>DB_CACHE_SIZE 也是这些等待出现频率的决定因素。有问题的散列区域（Hash-area）连接应当出现在PGA 内存中，但它们也会消耗大量内存，从而在顺序读取时导致大量等待。它们也可能以直接路径读／写等待的形式出现。</p>
<p>Free Buffer Wait: 释放缓冲区。<br>这种等待表明系统正在等待内存中的缓冲，因为内存中已经没有可用的缓冲空间了。如果所有SQL 都得到了调优，这种等待可能表示你需要增大DB_BUFFER_CACHE。释放缓冲区等待也可能表示不加选择的SQL 导致数据溢出了带有索引块的缓冲存储器，没有为等待系统处理的特定语句留有缓冲区。<br>这种情况通常表示正在执行相当多数量的DML（插入／更新／删除），并且可能说明DBWR 写的速度不够快，缓冲存储器可能充满了相同缓冲器的多个版本，从而导致效率非常低。为了解决这个问题，可能需要考虑增加检查点、利用更多的DBWR 进程，或者增加物理磁盘的数量。</p>
<p>Buffer Busy Wait: 缓冲区忙。<br>该等待事件表示正在等待一个以unshareable方式使用的缓冲区，或者表示当前正在被读入buffercache。也就是当进程想获取或者操作某个block的时候却发现被别的进程在使用而出现等待。一般来说BufferBusy Wait不应大于1%。<br>检查缓冲等待统计部分（或V$WAITSTAT），看一下等待是否位于段头。如果是，可以考虑增加自由列表（freelist，对于Oracle8i DMT）或者增加freelist groups.<br>其修改语法为：</p>
<pre><code>SQL&gt; alter table sp_item storage (freelists 2);
Table altered。
</code></pre>
<p>对于Oracle8i而言，增加freelist参数，在很多时候可以明显缓解等待，如果使用LMT，也就是 Local Manangement Tablespace，区段的管理就相对简单还可以考虑修改数据块的pctused\pctfree值，比如增大pctfree可以扩大数据的分布，在某种程度上就可以减少热点块的竞争。</p>
<p>如果这一等待位于undo header，可以通过增加回滚段（rollback segment）来解决缓冲区的问题。<br>如果等待位于undo block上，我们可能需要检查相关应用，适当减少大规模的一致性读取，或者降低一致性读取(consistent read)的表中的数据密度或者增大DB_CACHE_SIZE。<br>如果等待处于data block，可以考虑将频繁并发访问的表或数据移到另一数据块或者进行更大范围的分布（可以增加pctfree 值，扩大数据分布，减少竞争），以避开这个”热点”数据块，或者可以考虑增加表中的自由列表或使用本地化管理的表空间（LocallyManaged Tablespaces）。<br>如果等待处于索引块，应该考虑重建索引、分割索引或使用反向键索引。反向键索引在很多情况下，可以极大地缓解竞争，其原理有点类似于hash分区的功效。反向键索引（reverse key index）常建在一些值是连续增长的列上，例如列中的值是由sequence产生的。</p>
<p>为了防止与数据块相关的缓冲忙等待，也可以使用较小的块：在这种情况下，单个块中的记录就较少，所以这个块就不是那么”繁忙”；或者可以设置更大的pctfree,使数据扩大物理分布，减少记录间的热点竞争。<br>在执行DML (insert/update/ delete)时，Oracle向数据块中写入信息，对于多事务并发访问的数据表，关于ITL的竞争和等待可能出现，为了减少这个等待，可以增加initrans，使用多个ITL槽。<br>以下是一个生产系统v$waitstat 试图所显示的等待信息:</p>
<pre><code>SQL&gt; select * from v$waitstat where count&lt;&gt;0 or time &lt;&gt;0;
CLASS      COUNT TIME
------------------ ---------- ----------
data block       453   6686
undo header      391   1126
undo block      172      3
</code></pre>
<p>latch free: latch释放<br>latch 是一种低级排队机制，用于保护SGA 中共享内存结构。<br>latch就像是一种快速地被获取和释放的内存锁。latch用于防止共享内存结构被多个用户同时访问。如果latch不可用，就会记录latch释放失败(latch free miss)。<br>有两种与闩有关的类型：<br>■ 立刻。<br>■ 可以等待。<br>假如一个进程试图在立刻模式下获得闩，而该闩已经被另外一个进程所持有，如果该闩不能立刻可用的话，那么该进程就不会为获得该闩而等待。它将继续执行另一个操作。<br>大多数latch 问题都与以下操作相关：<br>没有很好的是用绑定变量（library cache latch）、重作生成问题（redoallocation latch）、缓冲存储器竞争问题（cache buffers LRUchain），以及buffer cache中的存在”热点”块（cache buffers chain）。<br>通常我们说，如果想设计一个失败的系统，不考虑绑定变量，这一个条件就够了，对于异构性极强的系统，不使用绑定变量的后果是极其严重的。<br>另外也有一些latch 等待与bug 有关，应当关注Metalink 相关bug 的公布及补丁的发布。<br>当latch miss ratios大于0.5%时，就应当研究这一问题。<br>Oracle 的 latch 机制是竞争，其处理类似于网络里的CSMA/CD，所有用户进程争夺latch，对于愿意等待类型(willing-to-wait)的latch,如果一个进程在第一次尝试中没有获得latch,那么它会等待并且再尝试一次,如果经过_spin_count 次争夺不能获得latch, 然后该进程转入睡眠状态，持续一段指定长度的时间，然后再次醒来，按顺序重复以前的步骤.在8i/9i 中默认值是 _spin_count=2000。<br>如果SQL语句不能调整，在8.1.6版本以上，Oracle提供了一个新的初始化参数: CURSOR_SHARING，可以通过设置CURSOR_SHARING = force 在服务器端强制绑定变量。设置该参数可能会带来一定的副作用，对于Java的程序，有相关的bug，具体应用应该关注Metalink的bug公告。</p>
<p>enqueue<br>enqueue 是一种保护共享资源的锁定机制。该锁定机制保护共享资源，如记录中的数据，以避免两个人在同一时间更新同一数据。enqueue 包括一个排队机制，即FIFO（先进先出）排队机制。<br>Enqueue 等待常见的有ST、HW 、TX 、TM 等<br>ST enqueue 用于空间管理和字典管理的表空间(DMT)的分配。对于支持LMT 的版本，可以考虑使用本地管理表空间，对于Oracle8i，因为相关bug 不要把临时表空间设置为LMT. 或者考虑预分配一定数量的区。<br>HW enqueue 指段的高水位标记相关等待；手动分配适当区段可以避免这一等待。<br>TX 是最常见的enqueue 等待。TX enqueue 等待通常是以下三个问题之一产生的结果。<br>第一个问题是唯一索引中的重复索引，你需要执行提交（commit）/回滚（rollback）操作来释放enqueue。<br>第二个问题是对同一位图索引段的多次更新。因为单个位图段可能包含多个行地址（rowid），所以当多个用户试图更新同一段时，等待出现。直到提交或回滚，enqueue 释放。<br>第三个问题，也是最可能发生的问题是多个用户同时更新同一个块。如果没有自由的ITL 槽，就会发生块级锁定。通过增大initrans 和/或maxtrans 以允许使用多个ITL 槽，或者增大表上的pctfree值，就可以很轻松地避免这种情况。<br>TM enqueue 在DML 期间产生，以避免对受影响的对象使用DDL。如果有外键，一定要对它们进行索引，以避免这种常见的锁定问题。</p>
<p>Log Buffer Space: 日志缓冲空间<br>当你将日志缓冲（log buffer）产生重做日志的速度比LGWR 的写出速度快，或者是当日志转换（log switch）太慢时，就会发生这种等待。为解决这个问题，可以增大日志文件的大小，或者增加日志缓冲器的大小.<br>另外一个可能的原因是磁盘I/O 存在瓶颈，可以考虑使用写入速度更快的磁盘。</p>
<p>log file switch (archiving needed)<br>这个等待事件出现时通常是因为日志组循环写满以后，第一个日志归档尚未完成，出现该等待可能是 IO 存在问题。<br>解决办法：<br>可以考虑增大日志文件和增加日志组<br>移动归档文件到快速磁盘<br>调整log_archive_max_processes .</p>
<p>log file switch (checkpoint incomplete): 日志切换（检查点未完成）<br>当你的日志组都写完以后，LGWR 试图写第一个log file，如果这时数据库没有完成写出记录在第一个log file 中的dirty 块时（例如第一个检查点未完成），该等待事件出现。<br>该等待事件说明你的日志组过少或者日志文件过小。<br>你可能需要增加你的日志组或日志文件大小。</p>
<p>Log File Switch: 日志文件转换<br>所有的提交请求都需要等待”日志文件转换（必要的归档）”或”日志文件转换（chkpt.不完全）”。确保归档磁盘未满，并且速度不太慢。 DBWR可能会因为输入/输出（I／O）操作而变得很慢。你可能需要增加更多或更大的重做日志，而且如果DBWxR是问题症结所在的话，可能需要增加数据库书写器。</p>
<p>log file sync: 日志文件同步<br>当一个用户提交或回滚数据时，LGWR 将session 会话的重做由redo buffer 写入到重做日志中。<br>log file sync 必须等待这一过程成功完成(Oracle 通过写redo log file 保证commit 成功的数据不丢失)，这个事件说明提交可能过于频繁，批量提交可以最大化LGWR 的效率，过分频繁的提交会引起LGWR频繁的激活，扩大了LGWR 的写代价。<br>为了减少这种等待事件，可以尝试每次提交更多的记录。<br>将重做日志置于较快的磁盘上，或者交替使用不同物理磁盘上的重做日志，以降低归档对LGWR的影响。<br>对于软RAID，一般来说不要使用RAID 5，RAID5 对于频繁写入得系统会带来较大的性能损失，可以考虑使用文件系统直接输入/输出，或者使用裸设备（raw device），这样可以获得写入的性能提高。</p>
<p>log file single write<br>该事件仅与写日志文件头块相关，通常发生在增加新的组成员和增进序列号时。头块写单个进行，因为头块的部分信息是文件号，每个文件不同。更新日志文件头这个操作在后台完成，一般很少出现等待，无需太多关注。</p>
<p>log file parallel write<br>从log buffer 写redo 记录到redo log 文件，主要指常规写操作(相对于log file sync)。<br>如果你的Log group 存在多个组成员，当flush log buffer 时，写操作是并行的，这时候此等待事件可能出现。<br>尽管这个写操作并行处理，直到所有I/O 操作完成该写操作才会完成(如果你的磁盘支持异步IO或者使用IO SLAVE，那么即使只有一个redo log file member,也有可能出现此等待)。<br>这个参数和log file sync 时间相比较可以用来衡量log file 的写入成本。通常称为同步成本率。</p>
<p>control file parallel write: 控制文件并行写<br>当server 进程更新所有控制文件时，这个事件可能出现。<br>如果等待很短，可以不用考虑。如果等待时间较长，检查存放控制文件的物理磁盘I/O 是否存在瓶颈。<br>多个控制文件是完全相同的拷贝，用于镜像以提高安全性。对于业务系统，多个控制文件应该存放在不同的磁盘上，一般来说三个是足够的，如果只有两个物理硬盘，那么两个控制文件也是可以接受的。在同一个磁盘上保存多个控制文件是不具备实际意义的。<br>减少这个等待，可以考虑如下方法：<br>减少控制文件的个数(在确保安全的前提下)<br>如果系统支持，使用异步IO<br>转移控制文件到IO 负担轻的物理磁盘</p>
<p>control file sequential read/ control file single write<br>控制文件连续读/控制文件单个写<br>对单个控制文件I/O 存在问题时，这两个事件会出现。<br>如果等待比较明显，检查单个控制文件，看存放位置是否存在I/O 瓶颈。<br>使用查询获得控制文件访问状态：<br>select P1 from V$SESSION_WAIT<br>where EVENT like ‘control file%’ and STATE=’WAITING’;<br>解决办法：<br>移动有问题的控制文件到快速磁盘<br>如果系统支持，启用异步I/O</p>
<p>direct path write: 直接路径写<br>该等待发生在，等待确认所有未完成的异步I/O 都已写入磁盘。<br>你应该找到I/O 操作频繁的数据文件，调整其性能。<br>也有可能存在较多的磁盘排序，临时表空间操作频繁，可以考虑使用Local 管理表空间，分成多个小文件，写入不同磁盘或者裸设备。</p>
<p>SQL*Net message from dblink<br>该等待通常指与分布式处理（从其他数据库中SELECT）有关的等待。<br>这个事件在通过DBLINKS 联机访问其他数据库时产生。如果查找的数据多数是静态的，可以考虑移动这些数据到本地表并根据需要刷新，通过快照或者物化视图来减少跨数据库的访问，会在性能上得到很大的提高。</p>
<p>slave wait: 从属进程等<br>Slave Wait 是Slave I/O 进程等待请求，是一个空闲参数，一般不说明问题。</p>
<p>2.2.4  High Load SQL 分析<br>对于一个特定的应用程序或者系统来讲，要调整优化其性能，最好的方法是检查程序的代码和用户使用的SQL语句。<br>如果使用了 level 5 级别的 snapshot ，那么statspack生成的报告中就会显示系统中高负荷SQL语句（High Load SQL）的信息，而其详细信息可以在 stats$sql_summary 表中查到。缺省情况下 snapshot 的级别是 level 5。<br>按照 buffer gets, physical reads, executions, memory usage andversion count 等参数的降序排列顺序，把SQL语句分为几个部分罗列在报告中。</p>
<p>2.2.5  报告的其他部分<br>statspack报告的其他部分包括了 Instance Activity Stats，TablespaceIO Stats，Buffer Pool Statistics，Bufferwait Statistics，Rollback Segment Stats，LatchActivity，Dictionary Cache Stats，LibraryCache Activity，SGA breakdown difference 以及init.ora 参数，等等。目前本文不对这些内容进行详细讨论，请参加其他详细文档。</p>
<p>2.3 trace session  （……）</p>
<p>2.4 基于成本的优化器技术内幕<br>Oracle基于成本的优化器（Oracle’s cost-based SQL optimizer ，简称CBO)，是Oracle里面非常复杂的一个部分, 它决定了Oracle里面每个SQL的执行路径。CBO是一项评价SQL语句和产生最好执行计划的具有挑战性的工作，所以也使它成Oracle最复杂的软件组成部分。<br>众所周知，SQL的执行计划，几乎是Oracle性能调整最重要的方面了。所以想要学会如何调整Oracle数据库的性能，就要学会如何对SQL进行调整，就需要深入透彻理解CBO。<br>CBO的执行路径，取决于一些外部因素，内部的Oracle统计数据，以及数据是如何分布的。<br>我们将要讨论下面的话题：<br>CBO的参数：我们从基本的优化器参数开始学习，然后学习每个优化器参数是如何影响Oracle的优化器的执行的。</p>
<p>CBO的统计：这里我们将讨论，使用Analyze或者DBMS_STATS来收集正确的统计数据，对Oracle 优化器而言，是多么的重要。我们还将学习如何把优化器的统计数据，从一个系统拷贝到另外一个系统，这样可以确保开发环境和产品数据库环境下，SQL的执行路径不会变化。</p>
<p>下面我们开始讨论CBO优化模式以及影响CBO的Oracle参数</p>
<p>2.4.1  CBO的参数<br>CBO受一些重要参数的影响，修改这些参数后可以看到CBO性能上戏剧性的变化。首先从设置CBO的optimizer_mode参数开始，然后讨论其他重要参数的设置。</p>
<p>在 Oracle 9i 中，optimizer_mode 参数有四种取值，决定了四种优化模式：rule, choose, all_rows, 和 first_rows，其中 rule 和 choose 两种模式表示目前已经过时的基于规则的优化器模式（rule-based optimizer，简称RBO），所以我们在此着重讨论后两种CBO模式。</p>
<p>优化模式的设置可以在系统级进行，也可以对某个会话（session）进行设置，或者对某个SQL语句进行设置。对应的语句如下：<br>alter system set optimizer_mode=first_rows_10;<br>alter session set optimizer_goal = all_rows;<br>select /*+ first_rows(100) */ from student;</p>
<p>我们首先需要知道对一个SQL语句来说，什么是最好的执行计划（the best execution plan）？是使SQL语句返回结果的速度最快，还是使SQL语句占用系统资源最少？显然，这个答案取决于数据库的处理方式。</p>
<p>举一个简单的例子，比如有下列SQL语句：<br>select customer_name<br>from<br>   customer<br>where<br>   region = ‘south’<br>order by<br>   customer_name;</p>
<p>如果最好的执行计划是返回结果的速度最快，那么就需要使用region 列和 customer_name 列上的索引，从 customer 表中按照正确的顺序快速读取所有的列，而不用管是否从物理上读取了很多不连续的数据块导致的大量IO操作。（见下图）</p>
<p>假设这个执行计划从开始到返回结果耗时0.0001 秒，同时产生了 10000 个 db_block_gets ，但是如果你的目标是计算资源的最小化呢？如果这个SQL语句是在一个批处理程序中执行，也许对返回结果的速度要求就不那么重要了，而另一个执行计划则可能耗费更少的系统资源。<br>在下图所示的例子中，并行的全表扫描由于不需要按照排序重新读取数据块，所以耗系统资源较少，并且IO操作也不多。当然，由于SQL语句执行过程中没有排序，得到预期结果的时间就长了，而资源耗费少了。假设这个执行计划从开始到返回结果耗时 10 秒，同时产生了 5000 个 db_block_gets</p>
<p>Oracle提供了几个optimizer_mode 的设置参数，使你能够得到想要的最好的执行计划。</p>
<p>optimizer_mode = first_rows<br>设置为这种CBO模式以后，SQL语句返回结果的速度会尽可能的快，而不管系统全部的查询是否会耗时较长或者耗系统资源过多。由于利用索引会使查询速度加快，所以 first_rows 优化模式会在全表扫描上进行索引扫描。这种优化模式一般适合于一些OLTP系统，满足用户能够在较短时间内看到较小查询结果集的要求。</p>
<p>optimizer_mode = all_rows<br>设置为这种CBO模式以后，将保证消耗的所有计算资源最小，尽管有时查询结束以后没有结果返回。all_rows 的优化模式更倾向于全表扫描，而不是全索引扫描和利用索引排序，因此这种优化模式适合于数据查看实时性不是那么强的数据仓库、决策支持系统和面向批处理的数据库（batch-oriented databases）等。</p>
<p>optimizer_mode = first_rows_n<br>Oracle 9i 对一些预期返回结果集的数据量小的SQL语句优化模式进行了加强，增加了四个参数值：first_rows_1、first_rows_10、 first_rows_100、first_rows_1000。CBO通过 first_rows_n 中的 n 值，决定了返回结果集数量的基数，我们可能仅仅需要查询结果集中的一部分，CBO就根据这样的 n 值来决定是否使用索引扫描。</p>
<p>optimizer_mode = rule<br>基于规则的优化器模式，RBO，是早期Oracle版本使用过的一种优化模式。由于RBO不支持自1994年Oracle版本的新特性，如 bitmap indexes，table partitions，function-based indexes等，所以在以后Oracle版本中已经不再更新RBO，并且也不推荐用户使用RBO这种优化模式了。</p>
<p>从上面的讨论可以看出，optimizer_mode 参数的设置对CBO是非常重要的，决定了CBO的基本模式，同时还有一些其他的参数也对CBO有着极大的影响。由于CBO的重要性，Oracle提供了一些系统级的参数来调整CBO的全局性能，这些调整参数包括索引扫描与全部扫描的选择、表连接方式的选择，等等。下面简单讨论一下。</p>
<p>optimizer_index_cost_adj<br>这个参数用于调整使用索引的访问路径的成本算法，参数值越小，索引访问的成本就越低。</p>
<p>optimizer_index_caching<br>这个参数告诉Oracle在内存缓冲区中索引的数量。该参数的设置会影响CBO如何决定使用表连接（嵌套循环）的索引还是使用全表扫描。</p>
<p>db_file_multiblock_read_count<br>这个参数的值被设置较大的时候，CBO就会认为离散的、多数据块的读取会比顺序读取的代价更低，使得CBO更倾向于全表扫描。</p>
<p>parallel_automatic_tuning<br>这个参数值被设置为 on 的时候，表示使用并行的全表扫描，由于并行的全表扫描比较快，所以CBO认为索引的访问是高成本的，同时就更倾向于全表扫描。</p>
<p>hash_area_size<br>如果不使用 pga_aggregate_target 参数的话，该参数有效。该参数的设置大小决定CBO是否更加倾向于 hash joins ，而不是嵌套循环和表连接的索引合并。</p>
<p>sort_area_size<br>如果不使用 pga_aggregate_target 参数的话，该参数有效。该参数的设置大小影响CBO决定是否进行索引访问和结果集的排序，参数值越大，在内存中排序的可能性就越大，CBO也就更加倾向于排序。</p>
<p>由于对这些参数值的修改会影响到系统中成千上万的SQL语句的执行计划，所以Oracle并不推荐修改这些参数的缺省值。</p>
<p>在对CBO的参数有了大致的了解以后，下面讨论如何根据提供给CBO的数据帮助CBO制定出一个好的执行计划。</p>
<p>2.4.2  CBO的统计<br>对于CBO来说，最重要的是定义和管理好你的统计数据，为了使CBO能够为你的SQL语句产生一个最好的执行计划，必须要有与SQL语句相关的表和索引统计数据。只有当CBO知道了相关的信息，如表的大小、分布、基数以及列值的可选性等，才能对SQL语句作出正确的判断，从而得到最好的执行计划。</p>
<p>下面讨论一下如何获得高质量的CBO统计数据，如何为你的数据库系统创建一个适当的CBO环境。</p>
<p>CBO产生最好执行计划的能力来自于统计数据的有效性，获得统计数据的比较过时的方法是 analyze table 和 dbms_utility ，这两种方法对SQL语句的性能有一些危害，因为我们知道，CBO是使用对象统计数据（object statistics）来为所有的SQL语句选择最好的执行计划。</p>
<p>dbms_stats 应用功能包是产生统计数据较好的方法，特别对大型分区表而言。下面看一个使用 dbms_stats 的例子。</p>
<pre><code>exec dbms_stats.gather_schema_stats(
  ownname          =&gt;&#39;SCOTT&#39;,
 options            =&gt;&#39;GATHER AUTO&#39;,
  estimate_percent    =&gt; dbms_stats.auto_sample_size,
  method_opt        =&gt; &#39;for allcolumns size repeat&#39;,
  degree           =&gt; 34
   )
</code></pre>
<p>上面例子中的options参数的几个可选值需要说明一下。<br>GATHER  重新分析整个schema，产生统计数据；</p>
<p>  GATHER EMPTY 仅分析那些还没有统计数据的表；</p>
<p>  GATHER STALE 仅重新分析那些发生了10％变化的表（变化原因可能是 inserts, updates ,deletes ）</p>
<p>  GATHER AUTO 仅重新分析那些还没有统计数据和发生了10％变化的表，该选项相当于 GATHER EMPTY 和 GATHER STALE 同时使用。</p>
<p>使用 GATHER AUTO 和 GATHER STALE 两个选项需要进行监控，如果你执行了 ALTER TABLE XXX MONITORING 命令，Oracle利用 dba_tab_modifications 视图跟踪表的变化，记录了最近一次统计数据分析以来的 insert , update , delete 的准确记录数。</p>
<pre><code>SQL&gt; desc dba_tab_modifications;
 Name                    Type
 -----------------             ---------------
 TABLE_OWNER         VARCHAR2(30)
 TABLE_NAME          VARCHAR2(30)
 PARTITION_NAME       VARCHAR2(30)
 SUBPARTITION_NAME   VARCHAR2(30)
 INSERTS                NUMBER
 UPDATES               NUMBER
 DELETES               NUMBER
 TIMESTAMP            DATE
 TRUNCATED            VARCHAR2(3)
</code></pre>
<p>比较有趣的一个选项是 GATHER STALE ，比如在一个数据更新频繁的OLTP系统中，几乎所有的统计数据都会很快的过时，而我们必须记住GATHER STALE 选项是在表中10％的记录发生变化时才对该表重新分析产生统计数据，因此除了只读表以外的所有表几乎使用 GATHER STALE 选项重新分析产生统计数据，所以 GATHER STALE 选项主要还是用于一些主要是只读表组成的系统中。</p>
<p>在上面使用 dbms_stats 的例子中，我们看到了一个参数 estimate_percent ，它的值是dbms_stats.auto_sample_size, 这个参数值是 Oracle 9i 才开始使用的，这个参数值的出现极大方便了统计数据的分析产生。<br>我们知道，统计数据的质量越高，CBO产生最好执行计划的能力就越强，但是由于数据库统计采样大小的问题，对一个大型数据库系统做一个完整的统计数据分析产生将会耗时数天，最好的办法就是在高质量的统计数据和数据库统计采样大小之间得到一个平衡点。<br>在早一些的Oracle版本中，为了得到统计数据，DBA不得不猜测一个最好的数据采样大小百分比。但是从 Oracle 9i 开始，可以通过 dbms_stats 包来自己指定 estimate_percent 参数的值了，那就是dbms_stats.auto_sample_size<br>通过这种方式设置了自动采样大小以后，我们可以通过下列数据字典视图的 sample_size 字段来验证这些自动产生的统计采样大小。</p>
<pre><code>DBA_ALL_TABLES
DBA_INDEXES
DBA_IND_PARTITIONS
DBA_IND_SUBPARTITIONS
DBA_OBJECT_TABLES
DBA_PART_COL_STATISTICS
DBA_SUBPART_COL_STATISTICS
DBA_TABLES
DBA_TAB_COLS
DBA_TAB_COLUMNS
DBA_TAB_COL_STATISTICS
DBA_TAB_PARTITIONS
DBA_TAB_SUBPARTITIONS
</code></pre>
<p>使用自动统计采样以后，Oracle会根据表的大小和列值的分布在5％到20％之间取值。记住：你的统计数据质量越高，CBO作出的决定就越对你有利。</p>
<p>现在我们对CBO统计数据应该有一些了解了，下面来看看在一个成功的Oracle系统是如何管理CBO统计数据。</p>
<p>2.4.3  CBO的正确环境<br>成功使用CBO的关键是稳定性，下面是一些成功使用CBO的基本事项。</p>
<p>●只在必需的时候才进行统计数据的重新分析<br>Oracle DBA们最容易犯的一个普遍错误就是经常性的对系统的统计数据进行重新分析。记住：做这件事的唯一目的是改变SQL语句的执行计划，如果这个执行计划没有被破坏，就不要去修复它。如果你对SQL语句的性能还满意的话，重新分析产生统计数据以后可能会产生较大的性能问题，并给开发团队带来影响。实际运用中，也是极少数的Oracle系统才会周期性的对统计数据进行重新分析。<br>一般来讲，一个数据库应用系统的基本架构是不会轻易改变，大数据量的表仍然是很大，索引列的分布、基数值等等也很少变化。只有下列几种情况的数据库才可能经常对整个系统的统计数据重新分析：<br>1、用于数据分析的数据库<br>   有一些由于科学试验数据分析的数据库系统，经常会更换整个一套的试验数据，那么这种情况下当数据库重新load了一套数据以后，可以立即重新对统计数据进行分析。<br>2、高度变化的数据库<br>   这是极少数的例子，表的大小或者索引列的数据在剧烈的变化，比如一张表有100条记录，一周以后就变成10000条记录。这种情况下也可以考虑周期性的进行统计数据分析。</p>
<p>●强迫开发人员调整自己的SQL<br>很多开发人员错误的认为，他们的任务就是编写SQL语句然后从数据库中获得正确的数据。但是实际上编写出SQL语句只是开发人员一半的工作，在一个成功的Oracle应用系统中，会要求开发人员的SQL语句采用最优化的方式访问数据库，并且保证SQL语句的执行计划在新的SQL之间的可移植性。<br>令人惊讶的是，在许多Oracle应用系统中都不怎么考虑具体SQL语句的执行计划，认为CBO是很智能的，无论如何都可以为我们提供最好的SQL语句执行计划。<br>同一个查询在SQL语句中可能有不同方式的写法，而每一种写法都可能有不同的执行计划。观察下面的例子，每一个查询的结果都是一样的，但是执行计划却相去甚远。</p>
<p>– 使用了不正确的子查询</p>
<pre><code>select
  book_title
from
  book
where
  book_key not in (select book_key from sales);
 
Execution Plan
----------------------------------------------------------
0      SELECT STATEMENT Optimizer=CHOOSE (Cost=1Card=1 Bytes=64)
1    0   FILTER
2    1     TABLE ACCESS (FULL) OF &#39;BOOK&#39;(Cost=1 Card=1 Bytes=64)
3    1     TABLE ACCESS (FULL) OF &#39;SALES&#39;(Cost=1 Card=5 Bytes=25)
</code></pre>
<p>– 使用了两张表的外连接</p>
<pre><code>select
  book_title
from
  book  b,
  sales  s
where
  b.book_key = s.book_key(+) 
and
  quantity is null;

Execution Plan
----------------------------------------------------------
0   SELECT STATEMENT Optimizer=CHOOSE (Cost=3 Card=100 Bytes=8200)

1  0 FILTER
2  1   FILTER
3  2     HASH JOIN (OUTER)
4  3      TABLE ACCESS (FULL) OF &#39;BOOK&#39; (Cost=1Card=20 Bytes=1280)
5  3      TABLE ACCESS (FULL) OF &#39;SALES&#39; (Cost=1Card=100 Bytes=1800)


-- 使用了三个正确的子查询
select
  book_title
from
  book
where
  book_title not in (
               select
               distinct
                 book_title
               from
                 book,
                 sales
               where
                 book.book_key = sales.book_key
               and
                 quantity &gt; 0);

Execution Plan
----------------------------------------------------------
0   SELECT STATEMENT Optimizer=CHOOSE (Cost=1 Card=1 Bytes=59)
1  0  FILTER
2  1   TABLE ACCESS (FULL) OF &#39;BOOK&#39; (Cost=1 Card=1 Bytes=59)
3  1   FILTER
4  3     NESTED LOOPS (Cost=6 Card=1 Bytes=82)
5  4       TABLE ACCESS (FULL) OF &#39;SALES&#39;(Cost=1 Card=5 Bytes=90)
6  4       TABLE ACCESS (BY INDEX ROWID) OF&#39;BOOK&#39; (Cost=1 Card=1)
7  6         INDEX (UNIQUE SCAN)OF &#39;PK_BOOK&#39; (UNIQUE)
</code></pre>
<p>我们看到，正确的SQL语句写法产生的执行计划是如此的不同。明智的开发人员知道如何去编写能够产生最好执行计划的SQL语句，明智的Oracle应用系统也会主动训练开发人员去编写最有效的SQL语句。</p>
<p>下面是一些帮助开发人员优化SQL语句的技巧：<br>1、 使用 autotrace 和 TKPROF 功能去分析SQL语句的执行计划；<br>2、 保证所有生产环境中的SQL语句都是在测试环境中经过优化的；<br>3、 制定一个性能优化的标准，而不是只要求开发人员编写出最快的SQL语句。根据这种标准，好的开发人员应该能够写出最有效的SQL语句。</p>
<p>●谨慎管理CBO统计数据<br>成功的Oracle系统会谨慎管理他们的CBO统计数据，以保证CBO在测试环境和生产环境中以同样的方式工作。一个聪明的DBA会在得到高质量的CBO统计数据以后，把这些统计数据移植到测试环境中，这样SQL语句的执行计划在测试环境和生产环境中就是一样的了。</p>
<p>对DBA来说，一个重要的工作就是收集和发布CBO统计数据，并随时保持一套当前运行环境的最精确的统计数据。在一些情况下，可能会有不止一套的优化统计数据。比如，对OLTP运行的最好的统计数据可能对数据仓库运行却不是最好的，在这种情况下，DBA就需要保持两套统计数据，并根据不同的运行条件导入系统。</p>
<p>可以使用 dbms_stats 包中的 export_system_stats 存储过程来完成CBO统计数据的导出。下面的例子中，我们把当前CBO统计数据导出到一张名叫 stats_table_oltp的表中。<br>dbms_stats.export_system_stats(‘stats_table_oltp’)</p>
<p>导出以后，我们就可以把这张表拷贝到别的实例中，当系统的运行模式改变以后，使用 dbms_stats 包中的 import_system_stats 存储过程来完成CBO统计数据的导入。<br>dbms_stats.import_system_stats(‘stats_table_oltp’)</p>
<p>●千万不要随便改动CBO参数的值<br>改动CBO相关参数的值是非常危险的，因为一个小小的改动可能就会对整个系统的执行性能带来极大的负面影响，只有在经过严格的系统测试以后才能改动这些参数的值。可能带来极大影响的参数值包括：optimizer_mode, optimizer_index_cost_adj, andoptimizer_index_caching。而其他参数，比如 hash_area_size ,sort_area_size，参数值的改变就不是那么危险了，可以在会话级进行改变以帮助CBO优化查询。</p>
<p>●保证静态的执行计划<br>成功的CBO应用会通过谨慎管理统计数据来锁定SQL执行计划，同时保证存储的优化计划的稳定性，或者在具体的SQL语句中加入一些细节上的提示。<br>记住：重新分析一个系统的统计数据，可能会导致成千上万的SQL语句改变其执行计划。许多Oracle应用系统要求所有的SQL语句在测试环境中经过验证，保证在功能上和生产环境是一致的。</p>
<p>2.4.4  CBO的思考<br>尽管我们已经对CBO的不少细节有了了解，但是由于随着Oracle新版本的不断推出，CBO变得越来越强大，同时也越来越复杂，我们仍然有许多关于CBO的知识需要学习。<br>下面是一些关于CBO调整的提纲性的建议，供准备进行CBO调整的DBA们思考。</p>
<p>●DBA可以提供一些Oracle参数的配置对CBO进行控制，但是只能在有限的环境下谨慎的改变这些参数；</p>
<p>●CBO依靠统计数据来产生SQL语句的优化的执行计划，可以通过 dbms_stats 包来分析、产生统计数据；</p>
<p>●DBA们的一项重要任务就是收集、管理CBO统计数据，这些数据可以被收集、存储，也可以在相关的实例中进行移植，以保证执行计划的连贯性。</p>
<p>●在没有使用export_system_stats 存储过程导出原来的统计数据以前，重新对系统的统计数据进行分析是十分危险的，因为成千上万的SQL语句的执行计划将可能全部改变，而你却不能恢复原来的 SQL性能。只有在系统的数据发生巨大变化时，才可能需要对整个系统的统计数据进行重新分析。</p>
<p>本小节是关于CBO的一些技术讨论，原文来自 Donald K. Burleson 在OTN上的一篇文章，具体URL路径是：<br><a target="_blank" rel="noopener" href="http://otn.oracle.com/oramag/webcolumns/2003/techarticles/burleson_cbo_pt1.html">http://otn.oracle.com/oramag/webcolumns/2003/techarticles/burleson_cbo_pt1.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Oracle_zsq/article/details/79956538">https://blog.csdn.net/Oracle_zsq/article/details/79956538</a>
 </p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Oracle/" rel="tag">Oracle</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-Java突击：03-Thread"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/04/15/Java%E7%AA%81%E5%87%BB%EF%BC%9A03-Thread/"
    >Java突击：03-Thread</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/15/Java%E7%AA%81%E5%87%BB%EF%BC%9A03-Thread/" class="article-date">
  <time datetime="2023-04-15T09:17:57.000Z" itemprop="datePublished">2023-04-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>JAVA 多线程并发<br>4.1.1. JAVA 并发知识库 </p>
<p>4.1.2. JAVA 线程实现/创建方式<br>4.1.2.1. 继承 Thread 类<br>Thread 类本质上是实现了 Runnable 接口的一个实例，代表一个线程的实例。启动线程的唯一方法就是通过 Thread 类的 start()实例方法。start()方法是一个 native 方法，它将启动一个新线程，并执行 run()方法。</p>
<pre><code>public class MyThread extends Thread &#123; 
 public void run() &#123; 
 System.out.println(&quot;MyThread.run()&quot;); 
 &#125; 
&#125; 
MyThread myThread1 = new MyThread(); 
myThread1.start(); 
</code></pre>
<p>4.1.2.2. 实现 Runnable 接口。<br>如果自己的类已经 extends 另一个类，就无法直接 extends Thread，此时，可以实现一个Runnable 接口。 </p>
<pre><code>public class MyThread extends OtherClass implements Runnable &#123; 
 public void run() &#123; 
 System.out.println(&quot;MyThread.run()&quot;); 
 &#125; 
&#125;
</code></pre>
<p>//启动 MyThread，需要首先实例化一个 Thread，并传入自己的 MyThread 实例： </p>
<pre><code>MyThread myThread = new MyThread(); 
Thread thread = new Thread(myThread); 
thread.start(); 
</code></pre>
<p>//事实上，当传入一个 Runnable target 参数给 Thread 后，Thread 的 run()方法就会调用</p>
<pre><code>target.run() 
public void run() &#123; 
 if (target != null) &#123; 
 target.run(); 
 &#125; 
&#125; 
</code></pre>
<p>4.1.2.3. ExecutorService、Callable<Class>、Future 有返回值线程<br>有返回值的任务必须实现 Callable 接口，类似的，无返回值的任务必须 Runnable 接口。执行Callable 任务后，可以获取一个 Future 的对象，在该对象上调用 get 就可以获取到 Callable 任务返回的 Object 了，再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程了。 </Class></p>
<pre><code>//创建一个线程池 
 ExecutorService pool = Executors.newFixedThreadPool(taskSize); 
 // 创建多个有返回值的任务 
 List&lt;Future&gt; list = new ArrayList&lt;Future&gt;(); 
 for (int i = 0; i &lt; taskSize; i++) &#123; 
 Callable c = new MyCallable(i + &quot; &quot;); 
 // 执行任务并获取 Future 对象 
 Future f = pool.submit(c); 
 list.add(f); 
 &#125; 
 // 关闭线程池 
 pool.shutdown(); 
 // 获取所有并发任务的运行结果 
 for (Future f : list) &#123; 
 // 从 Future 对象上获取任务的返回值，并输出到控制台 
 System.out.println(&quot;res：&quot; + f.get().toString()); 
 &#125; 
 
</code></pre>
<p>4.1.2.4. 基于线程池的方式<br>线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池。 </p>
<pre><code>// 创建线程池 
 ExecutorService threadPool = Executors.newFixedThreadPool(10); 
 while(true) &#123; 
 threadPool.execute(new Runnable() &#123; // 提交多个线程任务，并执行 
 @Override 
 public void run() &#123; 
 System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;); 
 try &#123; 
 Thread.sleep(3000); 
 &#125; catch (InterruptedException e) &#123; 
 e.printStackTrace(); 
 &#125; 
 &#125; 
 &#125;); 
 &#125; 
&#125; 
</code></pre>
<p>4.1.3. 4 种线程池<br> Java 里面线程池的顶级接口是 Executor，但是严格意义上讲 Executor 并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是 ExecutorService。 </p>
<p>4.1.3.1. newCachedThreadPool<br>创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。 </p>
<p>4.1.3.2. newFixedThreadPool<br>创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。 </p>
<p>4.1.3.3. newScheduledThreadPool<br>创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。  </p>
<pre><code>ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3); 
 scheduledThreadPool.schedule(newRunnable()&#123; 
 @Override 
 public void run() &#123; 
 System.out.println(&quot;延迟三秒&quot;); 
 &#125; 
 &#125;, 3, TimeUnit.SECONDS); 
scheduledThreadPool.scheduleAtFixedRate(newRunnable()&#123; 
 @Override 
 public void run() &#123; 
 System.out.println(&quot;延迟 1 秒后每三秒执行一次&quot;); 
 &#125; 
 &#125;,1,3,TimeUnit.SECONDS); 
</code></pre>
<p>4.1.3.4. newSingleThreadExecutor<br>Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！  </p>
<p>4.1.4. 线程生命周期(状态)<br>当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。<br>在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞(Blocked)和死亡(Dead)5 种状态。尤其是当线程启动以后，它不可能一直”霸占”着 CPU 独自运行，所以 CPU 需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换</p>
<p>4.1.4.1. 新建状态（NEW）<br>当程序使用 new 关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配内存，并初始化其成员变量的值 </p>
<p>4.1.4.2. 就绪状态（RUNNABLE）：<br>当线程对象调用了 start()方法之后，该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和程序计数器，等待调度运行。 </p>
<p>4.1.4.3. 运行状态（RUNNING）：<br>如果处于就绪状态的线程获得了 CPU，开始执行 run()方法的线程执行体，则该线程处于运行状态。 </p>
<p>4.1.4.4. 阻塞状态（BLOCKED）：<br>阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice，暂时停止运行。<br>直到线程进入可运行(runnable)状态，才有机会再次获得 cpu timeslice 转到运行(running)状态。阻塞的情况分三种： </p>
<p>等待阻塞（o.wait-&gt;等待对列）：<br>运行(running)的线程执行 o.wait()方法，JVM 会把该线程放入等待队列(waitting queue)中。</p>
<p>同步阻塞(lock-&gt;锁池)<br>运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池(lock pool)中。 </p>
<p>其他阻塞(sleep/join)<br>运行(running)的线程执行 Thread.sleep(long ms)或 t.join()方法，或者发出了 I/O 请求时，JVM 会把该线程置为阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O处理完毕时，线程重新转入可运行(runnable)状态。 </p>
<p>4.1.4.5. 线程死亡（DEAD）<br>线程会以下面三种方式结束，结束后就是死亡状态。 </p>
<p>正常结束 </p>
<ol>
<li>run()或 call()方法执行完成，线程正常结束。 </li>
</ol>
<p>异常结束<br>2. 线程抛出一个未捕获的 Exception 或 Error。 </p>
<p>调用 stop<br>3. 直接调用该线程的 stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。</p>
<p> 4.1.5. 终止线程 4 种方式<br>4.1.5.1. 正常运行结束<br> 程序运行结束，线程自动结束。 </p>
<p>4.1.5.2. 使用退出标志退出线程 </p>
<p>一般 run()方法执行完，线程就会正常结束，然而，常常有些线程是伺服线程。它们需要长时间的<br>运行，只有在外部某些条件满足的情况下，才能关闭这些线程。使用一个变量来控制循环，例如：<br>最直接的方法就是设一个 boolean 类型的标志，并通过设置这个标志为 true 或 false 来控制 while<br>循环是否退出，代码示例： </p>
<pre><code>public class ThreadSafe extends Thread &#123; 
 public volatile boolean exit = false; 
 public void run() &#123; 
 while (!exit)&#123; 
 //do something 
 &#125; 
 &#125; 
&#125; 
</code></pre>
<p>定义了一个退出标志 exit，当 exit 为 true 时，while 循环退出，exit 的默认值为 false.在定义 exit时，使用了一个 Java 关键字 volatile，这个关键字的目的是使 exit 同步，也就是说在同一时刻只能由一个线程来修改 exit 的值。</p>
<p>4.1.5.3. Interrupt 方法结束线程 </p>
<p>使用 interrupt()方法来中断线程有两种情况： </p>
<ol>
<li><p>线程处于阻塞状态：如使用了 sleep,同步锁的 wait,socket 中的 receiver,accept 等方法时，会使线程处于阻塞状态。当调用线程的 interrupt()方法时，会抛出 InterruptException 异常。<br>阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后 break 跳出循环状态，从而让我们有机会结束这个线程的执行。通常很多人认为只要调用 interrupt 方法线程就会结束，实际上是错的， 一定要先捕获 InterruptedException 异常之后通过 break 来跳出循环，才能正常结束 run 方法。 </p>
</li>
<li><p>线程未处于阻塞状态：使用 isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。</p>
<p> public class ThreadSafe extends Thread {<br>  public void run() {<br>  while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出<br>  try{<br>  Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出<br>  }catch(InterruptedException e){<br>  e.printStackTrace();<br>  break;//捕获到异常之后，执行 break 跳出循环<br>  }<br>  }<br>  }<br> } </p>
</li>
</ol>
<p>4.1.5.4. stop 方法终止线程（线程不安全） </p>
<p>程序中可以直接使用 thread.stop()来强行终止线程，但是 stop 方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出 ThreadDeatherror 的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用 stop 方法来终止线程。 </p>
<p>4.1.6. sleep 与 wait 区别 </p>
<ol>
<li>对于 sleep()方法，我们首先要知道该方法是属于 Thread 类中的。而 wait()方法，则是属于Object 类中的。</li>
<li>sleep()方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。 </li>
<li>在调用 sleep()方法的过程中，线程不会释放对象锁。 </li>
<li>而当调用 wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。 </li>
<li>1.7. start 与 run 区别 </li>
<li>start（）方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码。 </li>
<li>通过调用 Thread 类的 start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 </li>
<li>方法 run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行 run 函数当中的代码。 Run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程。 </li>
</ol>
<p>4.1.8. JAVA 后台线程 </p>
<ol>
<li>定义：守护线程–也称“服务线程”，他是后台线程，它有一个特性，即为用户线程 提供 公共服务，在没有用户线程可服务时会自动离开。 </li>
<li>优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。 </li>
<li>设置：通过 setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程的方式是在 线程对象创建 之前 用线程对象的 setDaemon 方法。 </li>
<li>在 Daemon 线程中产生的新线程也是 Daemon 的。 </li>
<li>线程则是 JVM 级别的，以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的生命周期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程依旧是活跃的。 </li>
<li>example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资源。 </li>
<li>生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依赖于系统，与系统“同生共死”。<br>当 JVM 中所有的线程都是守护线程的时候，JVM 就可以退出了；如果还有一个或以上的非守护线程则 JVM 不会退出。 </li>
</ol>
<p>4.1.9. JAVA 锁<br>4.1.9.1. 乐观锁 </p>
<p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。<br>java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。 </p>
<p>4.1.9.2. 悲观锁 </p>
<p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。<br>java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如 RetreenLock。 </p>
<p>4.1.9.3. 自旋锁 </p>
<p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。<br>线程自旋是需要消耗 cup 的，说白了就是让 cup 在做无用功，如果一直获取不到锁，那线程也不能一直占用 cup 自旋做无用功，所以需要设定一个自旋等待的最大时间。<br>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。 </p>
<p>自旋锁的优缺点<br>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！<br>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，<br>其它需要 cup 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；自旋锁时间阈值（1.6 引入了适应性自旋锁）<br>自旋锁的目的是为了占着 CPU 的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！  </p>
<p>JVM 对于自旋周期的选择，jdk1.5 这个限度是一定的写死的，在 1.6 引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时 JVM 还针对当前 CPU 的负荷情况做了较多的优化，如果平均负载小于 CPUs 则一直自旋，如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞，如果正在自旋的线程发现 Owner 发生了变化则延迟自旋时间（自旋计数）或进入阻塞，如果 CPU 处于节电模式则停止自旋，自旋时间的最坏情况是 CPU的存储延迟（CPU A 存储了一个数据，到 CPU B 得知这个数据直接的时间差），自旋时会适当放弃线程优先级之间的差异。 </p>
<p>自旋锁的开启<br>JDK1.6 中-XX:+UseSpinning 开启；<br>-XX:PreBlockSpin=10 为自旋次数；<br>JDK1.7 后，去掉此参数，由 jvm 控制； </p>
<p>4.1.9.4. Synchronized 同步锁 </p>
<p>synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁，同时属于可重入锁。<br>Synchronized 作用范围 </p>
<ol>
<li>作用于方法时，锁住的是对象的实例(this)； </li>
<li>当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8 则是 metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； </li>
<li>synchronized 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。<br>Synchronized 核心组件 </li>
</ol>
<ol>
<li>Wait Set：哪些调用 wait 方法被阻塞的线程被放置在这里； </li>
<li>Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； </li>
<li>Entry List：Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中； </li>
<li>OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为 OnDeck； </li>
<li>Owner：当前已经获取到所资源的线程被称为 Owner； </li>
<li>!Owner：当前释放锁的线程。<br>Synchronized 实现 </li>
</ol>
<ol>
<li>JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。 </li>
<li>Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。 </li>
<li>Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 </li>
<li>OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify或者 notifyAll 唤醒，会重新进去 EntryList 中。 </li>
<li>处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。 </li>
<li>Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。<br>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zqz_zqz/article/details/70233767">https://blog.csdn.net/zqz_zqz/article/details/70233767</a> </li>
<li>每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的 </li>
<li>synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。 </li>
<li>Java1.6，synchronized 进行了很多的优化，有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。 </li>
<li>锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀； </li>
<li>JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。 </li>
</ol>
<p>4.1.9.5. ReentrantLock<br>ReentantLock 继承接口 Lock 并实现了接口中定义的方法，他是一种可重入锁，除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。 </p>
<p>Lock 接口的主要方法 </p>
<ol>
<li>void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁. 相反, 如果锁已经被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁. </li>
<li>boolean tryLock()：如果锁可用, 则获取锁, 并立即返回 true, 否则返回 false. 该方法和lock()的区别在于, tryLock()只是”试图”获取锁, 如果锁不可用, 不会导致当前线程被禁用, 当前线程仍然继续往下执行代码. 而 lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行. </li>
<li>void unlock()：执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程并不持有锁, 却执行该方法, 可能导致异常的发生. </li>
<li>Condition newCondition()：条件对象，获取等待通知组件。该组件和当前的锁绑定，当前线程只有获取了锁，才能调用该组件的 await()方法，而调用后，当前线程将缩放锁。 </li>
<li>getHoldCount() ：查询当前线程保持此锁的次数，也就是执行此线程执行 lock 方法的次数。 </li>
<li>getQueueLength（）：返回正等待获取此锁的线程估计数，比如启动 10 个线程，1 个线程获得锁，此时返回的是 9 </li>
<li>getWaitQueueLength：（Condition condition）返回等待与此锁相关的给定条件的线程估计数。比如 10 个线程，用同一个 condition 对象，并且此时这 10 个线程都执行了condition 对象的 await 方法，那么此时执行此方法返回 10 </li>
<li>hasWaiters(Condition condition)：查询是否有线程等待与此锁有关的给定条件(condition)，对于指定 contidion 对象，有多少线程执行了 condition.await 方法 </li>
<li>hasQueuedThread(Thread thread)：查询给定线程是否等待获取此锁 </li>
<li>hasQueuedThreads()：是否有线程等待此锁 </li>
<li>isFair()：该锁是否公平锁 </li>
<li>isHeldByCurrentThread()： 当前线程是否保持锁锁定，线程的执行 lock 方法的前后分别是 false 和 true </li>
<li>isLock()：此锁是否有任意线程占用 </li>
<li>lockInterruptibly（）：如果当前线程未被中断，获取锁 </li>
<li>tryLock（）：尝试获得锁，仅在调用时锁未被线程占用，获得锁 </li>
<li>tryLock(long timeout TimeUnit unit)：如果锁在给定等待时间内没有被另一个线程保持，则获取该锁。 </li>
</ol>
<p>非公平锁<br>       JVM 按随机、就近原则分配锁的机制则称为不公平锁，ReentrantLock 在构造函数中提供了是否公平锁的初始化方式，默认为非公平锁。非公平锁实际执行的效率要远远超出公平锁，除非程序有特殊需要，否则最常用非公平锁的分配机制。<br>公平锁<br>       公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁，ReentrantLock 在构造函数中提供了是否公平锁的初始化方式来定义公平锁。 </p>
<p>ReentrantLock 与 synchronized </p>
<ol>
<li>ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作，与 synchronized 会被 JVM 自动解锁机制不同，ReentrantLock 加锁后需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况，使用 ReentrantLock 必须在 finally 控制块中进行解锁操作。 </li>
<li>ReentrantLock 相比 synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用 ReentrantLock。 </li>
</ol>
<p>ReentrantLock 实现 </p>
<pre><code>public class MyService &#123; 
 private Lock lock = new ReentrantLock(); 
 //Lock lock=new ReentrantLock(true);//公平锁 
 //Lock lock=new ReentrantLock(false);//非公平锁 
 private Condition condition=lock.newCondition();//创建 Condition 
 public void testMethod() &#123; 
 try &#123; 
 lock.lock();//lock 加锁 
 //1：wait 方法等待： 
 //System.out.println(&quot;开始 wait&quot;); 
 condition.await(); 
//通过创建 Condition 对象来使线程 wait，必须先执行 lock.lock 方法获得锁 
 //:2：signal 方法唤醒 
 condition.signal();//condition 对象的 signal 方法可以唤醒 wait 线程 
 for (int i = 0; i &lt; 5; i++) &#123; 
 System.out.println(&quot;ThreadName=&quot; + Thread.currentThread().getName()+ (&quot; &quot; + (i + 1))); 
 &#125; 
 &#125; catch (InterruptedException e) &#123; 
 e.printStackTrace(); 
 &#125; 
 finally 
&#123; 
 lock.unlock(); 
 &#125; 
 &#125; 
&#125;
</code></pre>
<p>Condition 类和 Object 类锁方法区别区别 </p>
<ol>
<li>Condition 类的 awiat 方法和 Object 类的 wait 方法等效 </li>
<li>Condition 类的 signal 方法和 Object 类的 notify 方法等效 </li>
<li>Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效 </li>
<li>ReentrantLock 类可以唤醒指定条件的线程，而 object 的唤醒是随机的 </li>
</ol>
<p>tryLock 和 lock 和 lockInterruptibly 的区别 </p>
<ol>
<li>tryLock 能获得锁就返回 true，不能就立即返回 false，tryLock(long timeout,TimeUnit unit)，可以增加时间限制，如果超过该时间段还没获得锁，返回 false </li>
<li>lock 能获得锁就返回 true，不能的话一直等待获得锁 </li>
<li>lock 和 lockInterruptibly，如果两个线程分别执行这两个方法，但此时中断这两个线程，lock 不会抛出异常，而 lockInterruptibly 会抛出异常。 </li>
</ol>
<p>4.1.9.6. Semaphore 信号量 </p>
<p> Semaphore 是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore 可以用来构建一些对象池，资源池之类的，比如数据库连接池 实现互斥锁（计数器为 1）<br>我们也可以创建计数为 1 的 Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。<br>代码实现<br>它的用法如下：</p>
<pre><code>// 创建一个计数阈值为 5 的信号量对象 
// 只能 5 个线程同时访问 
Semaphore semp = new Semaphore(5); 
try &#123; // 申请许可 
semp.acquire(); 
try &#123; 
// 业务逻辑 
&#125; catch (Exception e) &#123; 
&#125; finally &#123; 
// 释放许可 
semp.release(); 
&#125; 
&#125; catch (InterruptedException e) &#123; 
&#125;
</code></pre>
<p>Semaphore 与 ReentrantLock </p>
<p>Semaphore 基本能完成 ReentrantLock 的所有工作，使用方法也与之类似，通过 acquire()与release()方法来获得和释放临界资源。经实测，Semaphone.acquire()方法默认为可响应中断锁，与 ReentrantLock.lockInterruptibly()作用效果一致，也就是说在等待临界资源的过程中可以被Thread.interrupt()方法中断。<br>此外，Semaphore 也实现了可轮询的锁请求与定时锁的功能，除了方法名 tryAcquire 与 tryLock不同，其使用方法与 ReentrantLock 几乎一致。Semaphore 也提供了公平与非公平锁的机制，也可在构造函数中进行设定。<br>Semaphore 的锁释放操作也由手动进行，因此与 ReentrantLock 一样，为避免线程因抛出异常而无法正常释放锁的情况发生，释放锁的操作也必须在 finally 代码块中完成。 </p>
<p>4.1.9.7. AtomicInteger </p>
<p>首先说明，此处 AtomicInteger ，一个提供原子操作的 Integer 的类，常见的还有AtomicBoolean、AtomicInteger、AtomicLong、AtomicReference 等，他们的实现原理相同，区别在与运算对象类型的不同。令人兴奋地，还可以通过 AtomicReference<V>将一个对象的所有操作转化成原子操作。<br>我们知道，在多线程程序中，诸如++i 或 i++等运算不具有原子性，是不安全的线程操作之一。<br>通常我们会使用 synchronized 将该操作变成一个原子操作，但 JVM 为此类操作特意提供了一些同步类，使得使用更方便，且使程序运行效率变得更高。通过相关资料显示，通常AtomicInteger的性能是 ReentantLock 的好几倍。 </V></p>
<p>4.1.9.8. 可重入锁（递归锁） </p>
<p>本文里面讲的是广义上的可重入锁，而不是单指 JAVA 下的 ReentrantLock。可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在 JAVA 环境下 ReentrantLock 和 synchronized 都是 可重入锁。</p>
<p>4.1.9.9. 公平锁与非公平锁 </p>
<p>公平锁（Fair）<br>加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得 </p>
<p>非公平锁（Nonfair）<br>加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待 </p>
<ol>
<li>非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列 </li>
<li>Java 中的 synchronized 是非公平锁，ReentrantLock 默认的 lock()方法采用的是非公平锁。 </li>
</ol>
<p>4.1.9.10. ReadWriteLock 读写锁 </p>
<p>为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的，你只要上好相应的锁即可。<br>读锁<br>如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁<br>写锁<br>如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！<br>Java 中读写锁有个接口 java.util.concurrent.locks.ReadWriteLock ，也有具体的实现ReentrantReadWriteLock。 </p>
<p>4.1.9.11. 共享锁和独占锁 </p>
<p>java 并发包提供的加锁模式分为独占锁和共享锁。 </p>
<p>独占锁<br>独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。<br>独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。 </p>
<p>共享锁<br>共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。 </p>
<ol>
<li>AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。 </li>
<li>java 的并发包中提供了 ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。 </li>
</ol>
<p>4.1.9.12. 重量级锁（Mutex Lock） </p>
<p>Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为“重量级锁”。<br>JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。<br>JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 </p>
<p>4.1.9.13. 轻量级锁 </p>
<p>锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。 </p>
<p>锁升级<br>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。<br>“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场<br>景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。 </p>
<p>4.1.9.14. 偏向锁 </p>
<p>Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级<br>锁执行路径，因为轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换ThreadID 的时候依赖一次 CAS 原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的 CAS 原子指令的性能消耗）。<br>上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。 </p>
<p>4.1.9.15. 分段锁 </p>
<p>分段锁也并非一种实际的锁，而是一种思想 ConcurrentHashMap 是学习分段锁的最好实践 </p>
<p>4.1.9.16. 锁优化 </p>
<p>减少锁持有时间<br>只用在有线程安全要求的程序上加锁 </p>
<p>减小锁粒度<br>将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。<br>降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。 </p>
<p>锁分离<br>最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发 Java 五] </p>
<p>JDK 并发包<br>1。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如LinkedBlockingQueue 从头部取出，从尾部放数据 </p>
<p>锁粗化<br>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。 </p>
<p>锁消除<br>锁消除是在编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作，多数是因为程序员编码不规范引起。<br>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/39628e1180a9">https://www.jianshu.com/p/39628e1180a9</a> </p>
<p>4.1.10. 线程基本方法<br>线程相关的基本方法有 wait，notify，notifyAll，sleep，join，yield 等。  </p>
<p> 4.1.10.1. 线程等待（wait） </p>
<p>调用该方法的线程进入 WAITING 状态，只有等待另外线程的通知或被中断才会返回，需要注意的是调用 wait()方法后，会释放对象的锁。因此，wait 方法一般用在同步方法或同步代码块中。 </p>
<p>4.1.10.2. 线程睡眠（sleep） </p>
<p>sleep 导致当前线程休眠，与 wait 方法不同的是 sleep 不会释放当前占有的锁,sleep(long)会导致线程进入 TIMED-WATING 状态，而 wait()方法会导致当前线程进入 WATING 状态 </p>
<p>4.1.10.3. 线程让步（yield） </p>
<p>yield 会使当前线程让出 CPU 执行时间片，与其他线程一起重新竞争 CPU 时间片。一般情况下，优先级高的线程有更大的可能性成功竞争得到 CPU 时间片，但这又不是绝对的，有的操作系统对线程优先级并不敏感。 </p>
<p>4.1.10.4. 线程中断（interrupt） </p>
<p>中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这个线程本身并不会因此而改变状态(如阻塞，终止等)。 </p>
<ol>
<li><p>调用 interrupt()方法并不会中断一个正在运行的线程。也就是说处于 Running 状态的线程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已。 </p>
</li>
<li><p>若调用 sleep()而使线程处于 TIMED-WATING 状态，这时调用 interrupt()方法，会抛出InterruptedException,从而使线程提前结束 TIMED-WATING 状态。 </p>
</li>
<li><p>许多声明抛出 InterruptedException 的方法(如 Thread.sleep(long mills 方法))，抛出异常前，都会清除中断标识位，所以抛出异常后，调用 isInterrupted()方法将会返回 false。 </p>
</li>
<li><p>中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止一个线程 thread 的时候，可以调用 thread.interrupt()方法，在线程的 run 方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程。 </p>
</li>
</ol>
<p>4.1.10.5. Join 等待其他线程终止 </p>
<p>join() 方法，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞状态，回到另一个线程结束，当前线程再由阻塞状态变为就绪状态，等待 cpu 的宠幸。 </p>
<p>4.1.10.6. 为什么要用 join()方法？ </p>
<p>很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要在子线程结束后再结束，这时候就要用到 join() 方法。</p>
<pre><code>System.out.println(Thread.currentThread().getName() + &quot;线程运行开始!&quot;); 
 Thread6 thread1 = new Thread6(); 
 thread1.setName(&quot;线程 B&quot;); 
 thread1.join(); 
System.out.println(&quot;这时 thread1 执行完毕之后才能执行主线程&quot;); 
</code></pre>
<p>4.1.10.7. 线程唤醒（notify） </p>
<p>Object 类中的 notify() 方法，唤醒在此对象监视器上等待的单个线程，如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意的，并在对实现做出决定时发生，线程通过调用其中一个 wait() 方法，在对象的监视器上等待，直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程，被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争。类似的方法还有 notifyAll() ，唤醒再次监视器上等待的所有线程。 </p>
<p>4.1.10.8. 其他方法： </p>
<ol>
<li>sleep()：强迫一个线程睡眠Ｎ毫秒。 </li>
<li>isAlive()： 判断一个线程是否存活。 </li>
<li>join()： 等待线程终止。 </li>
<li>activeCount()： 程序中活跃的线程数。 </li>
<li>enumerate()： 枚举程序中的线程。 </li>
<li>currentThread()： 得到当前线程。 </li>
<li>isDaemon()： 一个线程是否为守护线程。 </li>
<li>setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) </li>
<li>setName()： 为线程设置一个名称。 </li>
<li>wait()： 强迫一个线程等待。</li>
<li>notify()： 通知一个线程继续运行。 </li>
<li>setPriority()： 设置一个线程的优先级。 </li>
<li>getPriority():：获得一个线程的优先级。 </li>
</ol>
<p>4.1.11. 线程上下文切换<br>巧妙地利用了时间片轮转的方式, CPU 给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后，继续服务下一任务，任务的状态保存及再加载, 这段过程就叫做上下文切换。时间片轮转的方式使多个任务在同一颗 CPU 上执行变成了可能。 </p>
<p>  4.1.11.1. 进程 </p>
<p>（有时候也称做任务）是指一个程序运行的实例。在 Linux 系统中，线程就是能并行运行并且与他们的父进程（创建他们的进程）共享同一地址空间（一段内存区域）和其他资源的轻量级的进程。 </p>
<p>4.1.11.2. 上下文 </p>
<p>是指某一时间点 CPU 寄存器和程序计数器的内容。 </p>
<p>4.1.11.3. 寄存器 </p>
<p>是 CPU 内部的数量较少但是速度很快的内存（与之对应的是 CPU 外部相对较慢的 RAM 主内存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来提高计算机程序运行的速度。 </p>
<p>4.1.11.4. 程序计数器 </p>
<p>是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体依赖于特定的系统。 </p>
<p>4.1.11.5. PCB-“切换桢” </p>
<p>上下文切换可以认为是内核（操作系统的核心）在 CPU 上对于进程（包括线程）进行切换，上下文切换过程中的信息是保存在进程控制块（PCB, process control block）中的。PCB 还经常被称作“切换桢”（switchframe）。信息会一直保存到 CPU 的内存中，直到他们被再次使用。 </p>
<p>4.1.11.6. 上下文切换的活动： </p>
<ol>
<li>挂起一个进程，将这个进程在 CPU 中的状态（上下文）存储于内存中的某处。 </li>
<li>在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复。 </li>
<li>跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程在程序中。 </li>
</ol>
<p>4.1.11.7. 引起线程上下文切换的原因 </p>
<ol>
<li>当前执行任务的时间片用完之后，系统 CPU 正常调度下一个任务； </li>
<li>当前执行任务碰到 IO 阻塞，调度器将此任务挂起，继续下一任务； </li>
<li>多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务； </li>
<li>用户代码挂起当前任务，让出 CPU 时间； </li>
<li>硬件中断； </li>
</ol>
<p>4.1.12. 同步锁与死锁<br>4.1.12.1. 同步锁 </p>
<p>当多个线程同时访问同一个数据时，很容易出现问题。为了避免这种情况出现，我们要保证线程同步互斥，就是指并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。 Java 中可以使用 synchronized 关键字来取得一个对象的同步锁。 </p>
<p>4.1.12.2. 死锁 </p>
<p>何为死锁，就是多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。 </p>
<p>4.1.13. 线程池原理 </p>
<p>线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。他的主要特点为：线程复用；控制最大并发数；管理线程。 </p>
<p>4.1.13.1. 线程复用 </p>
<p>每一个 Thread 的类都有一个 start 方法。 当调用 start 启动线程时 Java 虚拟机会调用该类的 run 方法。 那么该类的 run() 方法中就是调用了 Runnable 对象的 run() 方法。 我们可以继承重写 Thread 类，在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。 这就是线程池的实现原理。循环方法中不断获取 Runnable 是用 Queue 实现的，在获取下一个 Runnable 之前可以是阻塞的。 </p>
<p>4.1.13.2. 线程池的组成 </p>
<p>一般的线程池主要分为以下 4 个组成部分：  </p>
<ol>
<li><p>线程池管理器：用于创建并管理线程池 </p>
</li>
<li><p>工作线程：线程池中的线程 </p>
</li>
<li><p>任务接口：每个任务必须实现的接口，用于工作线程调度其运行 </p>
</li>
<li><p>任务队列：用于存放待处理的任务，提供一种缓冲机制<br>Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors，ExecutorService，ThreadPoolExecutor ，Callable 和 Future、FutureTask 这几个类。  ThreadPoolExecutor 的构造方法如下：</p>
<p> public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,<br> TimeUnit unit, BlockingQueue<Runnable> workQueue) {<br>  this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,<br>  Executors.defaultThreadFactory(), defaultHandler);<br> } </Runnable></p>
</li>
<li><p>corePoolSize：指定了线程池中的线程数量。 </p>
</li>
<li><p>maximumPoolSize：指定了线程池中的最大线程数量。 </p>
</li>
<li><p>keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多次时间内会被销毁。 </p>
</li>
<li><p>unit：keepAliveTime 的单位。 </p>
</li>
<li><p>workQueue：任务队列，被提交但尚未被执行的任务。 </p>
</li>
<li><p>threadFactory：线程工厂，用于创建线程，一般用默认的即可。 </p>
</li>
<li><p>handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。 </p>
</li>
</ol>
<p>4.1.13.3. 拒绝策略 </p>
<p>线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。<br>JDK 内置的拒绝策略如下： </p>
<ol>
<li>AbortPolicy ： 直接抛出异常，阻止系统正常运行。 </li>
<li>CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。 </li>
<li>DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 </li>
<li>DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。<br>以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际需要，完全可以自己扩展 RejectedExecutionHandler 接口。 </li>
</ol>
<p>4.1.13.4. Java 线程池工作过程 </p>
<ol>
<li>线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。 </li>
<li>当调用 execute() 方法添加一个任务时，线程池会做如下判断：<br>a) 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；<br>b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；<br>c) 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；<br>d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常 RejectExecutionException。 </li>
<li>当一个线程完成任务时，它会从队列中取下一个任务来执行。 </li>
<li>当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 </li>
</ol>
<p>4.1.14. JAVA 阻塞队列原理<br>阻塞队列，关键字是阻塞，先理解阻塞的含义，在阻塞队列中，线程阻塞有这样的两种情况： </p>
<ol>
<li><p>当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 </p>
</li>
<li><p>当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。</p>
</li>
<li><p>1.14.1. 阻塞队列的主要方法</p>
</li>
</ol>
<p>抛出异常：抛出一个异常；<br>特殊值：返回一个特殊值（null 或 false,视情况而定）<br>则塞：在成功操作之前，一直阻塞线程<br>超时：放弃前只在最大的时间内阻塞 </p>
<p>插入操作： </p>
<p>1：public abstract boolean add(E paramE)：将指定元素插入此队列中（如果立即可行且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则抛出 IllegalStateException。如果该元素是 NULL，则会抛出 NullPointerException 异常。<br>2：public abstract boolean offer(E paramE)：将指定元素插入此队列中（如果立即可行且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则返回 false。<br>3：public abstract void put(E paramE) throws InterruptedException： 将指定元素插入此队列中，将等待可用的空间（如果有必要） </p>
<pre><code>public void put(E paramE) throws InterruptedException &#123; 
 checkNotNull(paramE); 
 ReentrantLock localReentrantLock = this.lock; 
 localReentrantLock.lockInterruptibly(); 
 try &#123; 
 while (this.count == this.items.length) 
 this.notFull.await();//如果队列满了，则线程阻塞等待 
 enqueue(paramE); 
 
 localReentrantLock.unlock(); 
 &#125; finally &#123; 
 localReentrantLock.unlock(); 
 &#125; 
 &#125; 
 
</code></pre>
<p>4：offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入 BlockingQueue，则返回失败。  </p>
<p>获取数据操作： </p>
<p>1：poll(time):取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等 time 参数规定的时间,取不到时返回 null;<br>2：poll(long timeout, TimeUnit unit)：从 BlockingQueue 取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则直到时间超时还没有数据可取，返回失败。<br>3：take():取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断进入等待状态直到 BlockingQueue 有新的数据被加入。<br>4.drainTo():一次性从 BlockingQueue 获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 </p>
<p>4.1.14.2. Java 中的阻塞队列 </p>
<ol>
<li>ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。 </li>
<li>LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。 </li>
<li>PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。 </li>
<li>DelayQueue：使用优先级队列实现的无界阻塞队列。 </li>
<li>SynchronousQueue：不存储元素的阻塞队列。 </li>
<li>LinkedTransferQueue：由链表结构组成的无界阻塞队列。 </li>
<li>LinkedBlockingDeque：由链表结构组成的双向阻塞队列  </li>
</ol>
<p>4.1.14.3. ArrayBlockingQueue（公平、非公平） </p>
<p>用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。我们可以使用以下代码创建一个公平的阻塞队列： </p>
<pre><code>ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true); 
</code></pre>
<p>4.1.14.4. LinkedBlockingQueue（两个独立锁提高并发） </p>
<p>基于链表的阻塞队列，同 ArrayListBlockingQueue 类似，此队列按照先进先出（FIFO）的原则对元素进行排序。而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 </p>
<p>LinkedBlockingQueue 会默认一个类似无限大小的容量（Integer.MAX_VALUE）。 </p>
<p>4.1.14.5. PriorityBlockingQueue（compareTo 排序实现优先） </p>
<p>是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现compareTo()方法来指定元素进行排序规则，或者初始化 PriorityBlockingQueue 时，指定构造参数 Comparator 来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。 </p>
<p>4.1.14.6. DelayQueue（缓存失效、定时任务 ） </p>
<p>是一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将 DelayQueue 运用在以下应用场景： </p>
<ol>
<li>缓存系统的设计：可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期到了。 </li>
<li>定时任务调度：使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从DelayQueue 中获取到任务就开始执行，从比如 TimerQueue 就是使用 DelayQueue 实现的。 </li>
</ol>
<p>4.1.14.7. SynchronousQueue（不存储数据、可用于传递数据） </p>
<p>是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。<br>SynchronousQueue 可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用， SynchronousQueue 的吞吐量高于 LinkedBlockingQueue 和<br>ArrayBlockingQueue。 </p>
<p>4.1.14.8. LinkedTransferQueue </p>
<p>是一个由链表结构组成的无界阻塞 TransferQueue 队列。相对于其他阻塞队列，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。 </p>
<ol>
<li>transfer 方法：如果当前有消费者正在等待接收元素（消费者使用 take()方法或带时间限制的poll()方法时），transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer 方法会将元素存放在队列的 tail 节点，并等到该元素被消费者消费了才返回。 </li>
<li>tryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。<br>对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。 </li>
</ol>
<p>4.1.14.9. LinkedBlockingDeque </p>
<p>是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。<br>双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque 多了 addFirst，addLast，offerFirst，offerLast，<br>peekFirst，peekLast 等方法，以 First 单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以 Last 单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法 add 等同于 addLast，移除方法 remove 等效于 removeFirst。但是 take 方法却等同<br>于 takeFirst，不知道是不是 Jdk 的 bug，使用时还是用带有 First 和 Last 后缀的方法更清楚。<br>在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。 </p>
<p>4.1.15. CyclicBarrier、CountDownLatch、Semaphore 的用法<br>4.1.15.1. CountDownLatch（线程计数器 ） </p>
<p>CountDownLatch 类位于 java.util.concurrent 包下，利用它可以实现类似计数器的功能。比如有一个任务 A，它要等待其他 4 个任务执行完毕之后才能执行，此时就可以利用 CountDownLatch<br>来实现这种功能了。 </p>
<pre><code>final CountDownLatch latch = new CountDownLatch(2); 
 new Thread()&#123;public void run() &#123; 
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;); 
 Thread.sleep(3000); 
 System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;); 
 latch.countDown(); 
&#125;;&#125;.start(); 
 new Thread()&#123; public void run() &#123; 
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;); 
 Thread.sleep(3000); 
 System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;); 
 latch.countDown(); 
 &#125;;&#125;.start(); 
 System.out.println(&quot;等待 2 个子线程执行完毕...&quot;); 
 latch.await(); 
 System.out.println(&quot;2 个子线程已经执行完毕&quot;); 
 System.out.println(&quot;继续执行主线程&quot;); 
 &#125; 
</code></pre>
<p>4.1.15.2. CyclicBarrier（回环栅栏-等待至 barrier 状态再全部同时执行） </p>
<p>字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier 可以被重用。我们暂且把这个状态就叫做barrier，当调用 await()方法之后，线程就处于 barrier 了。<br>CyclicBarrier 中最重要的方法就是 await 方法，它有 2 个重载版本： </p>
<ol>
<li>public int await()：用来挂起当前线程，直至所有线程都到达 barrier 状态再同时执行后续任务； </li>
<li>public int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有线程没有到达 barrier 状态就直接让到达 barrier 的线程执行后续任务。</li>
</ol>
<p>具体使用如下，另外 CyclicBarrier 是可以重用的。</p>
<pre><code>public static void main(String[] args) &#123; 
 int N = 4; 
 CyclicBarrier barrier = new CyclicBarrier(N); 
 for(int i=0;i&lt;N;i++) 
 new Writer(barrier).start(); 
 &#125; 
 static class Writer extends Thread&#123; 
 private CyclicBarrier cyclicBarrier; 
 public Writer(CyclicBarrier cyclicBarrier) &#123; 
 this.cyclicBarrier = cyclicBarrier; 
 &#125; 
 @Override 
 public void run() &#123; 
 try &#123; 
 Thread.sleep(5000); //以睡眠来模拟线程需要预定写入数据操作 
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完毕，等待其他线程写入完毕&quot;); 
 cyclicBarrier.await(); 
 &#125; catch (InterruptedException e) &#123; 
 e.printStackTrace(); 
 &#125;catch(BrokenBarrierException e)&#123; 
 e.printStackTrace(); 
 &#125; 
 System.out.println(&quot;所有线程写入完毕，继续处理其他任务，比如数据操作&quot;); 
 &#125; 
 &#125; 
</code></pre>
<p>4.1.15.3. Semaphore（信号量-控制同时访问的线程个数） </p>
<p>Semaphore 翻译成字面意思为 信号量，Semaphore 可以控制同时访问的线程个数，通过acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。<br>Semaphore 类中比较重要的几个方法： </p>
<ol>
<li><p>public void acquire(): 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。 </p>
</li>
<li><p>public void acquire(int permits):获取 permits 个许可 </p>
</li>
<li><p>public void release() { } :释放许可。注意，在释放许可之前，必须先获获得许可。 </p>
</li>
<li><p>public void release(int permits) { }:释放 permits 个许可上面 4 个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法 </p>
</li>
<li><p>public boolean tryAcquire():尝试获取一个许可，若获取成功，则立即返回 true，若获取失败，则立即返回 false </p>
</li>
<li><p>public boolean tryAcquire(long timeout, TimeUnit unit):尝试获取一个许可，若在指定的时间内获取成功，则立即返回 true，否则则立即返回 false </p>
</li>
<li><p>public boolean tryAcquire(int permits):尝试获取 permits 个许可，若获取成功，则立即返回 true，若获取失败，则立即返回 false </p>
</li>
<li><p>public boolean tryAcquire(int permits, long timeout, TimeUnit unit): 尝试获取 permits个许可，若在指定的时间内获取成功，则立即返回 true，否则则立即返回 false </p>
</li>
<li><p>还可以通过 availablePermits()方法得到可用的许可数目。<br>例子：若一个工厂有 5 台机器，但是有 8 个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过 Semaphore 来实现： </p>
<p> int N = 8; //工人数<br>  Semaphore semaphore = new Semaphore(5); //机器数目<br>  for(int i=0;i&lt;N;i++)<br>  new Worker(i,semaphore).start();<br>  }<br>  static class Worker extends Thread{<br>  private int num;<br>  private Semaphore semaphore;<br>  public Worker(int num,Semaphore semaphore){<br>  this.num = num;<br>  this.semaphore = semaphore;<br>  } </p>
<p>  @Override<br>  public void run() {<br>  try {<br>  semaphore.acquire();<br>  System.out.println(“工人”+this.num+”占用一个机器在生产…”);<br>  Thread.sleep(2000);<br>  System.out.println(“工人”+this.num+”释放出机器”);<br>  semaphore.release();<br>  } catch (InterruptedException e) {<br>  e.printStackTrace();<br>  }<br>  } </p>
</li>
</ol>
<p>CountDownLatch 和 CyclicBarrier 都能够实现线程之间的等待，只不过它们侧重点不同；<br>CountDownLatch 一般用于某个线程 A 等待若干个其他线程执行完任务之后，它才执行；<br>而 CyclicBarrier 一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；<br>另外，CountDownLatch 是不能够重用的，而 CyclicBarrier 是可以重用的。<br>Semaphore 其实和锁有点类似，它一般用于控制对某组资源的访问权限。</p>
<p>4.1.16. volatile 关键字的作用（变量可见性、禁止重排序）<br>Java 语言提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作通知到其他线程。volatile 变量具备两种特性，volatile 变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取 volatile 类型的变量时总会返回最新写入的值。 </p>
<p>变量可见性<br>其一是保证该变量对所有线程可见，这里的可见性指的是当一个线程修改了变量的值，那么新的值对于其他线程是可以立即获取的。 </p>
<p>禁止重排序<br> volatile 禁止了指令重排。 </p>
<p>比 sychronized 更轻量级的同步锁<br>在访问 volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此 volatile 变量是一种比 sychronized 关键字更轻量级的同步机制。volatile 适合这种场景：一个变量被多个线程共享，线程直接给这个变量赋值。 </p>
<p> 当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到 CPU 缓存中。如果计算机有多个 CPU，每个线程可能在不同的 CPU 上被处理，这意味着每个线程可以拷贝到不同的 CPU cache 中。而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache 这一步。 </p>
<p>适用场景<br>值得说明的是对 volatile 变量的单次读/写操作可以保证原子性的，如 long 和 double 类型变量，但是并不能保证 i++这种操作的原子性，因为本质上 i++是读、写两次操作。在某些场景下可以代替 Synchronized。但是,volatile 的不能完全取代 Synchronized 的位置，只有在一些特殊的场<br>景下，才能适用 volatile。总的来说，必须同时满足下面两个条件才能保证在并发环境的线程安全：<br> （1）对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean flag = true）。<br>（2）该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。 </p>
<p>4.1.17. 如何在两个线程之间共享数据<br>Java 里面进行多线程通信的主要方式就是共享内存的方式，共享内存主要的关注点有两个：可见性和有序性原子性。Java 内存模型（JMM）解决了可见性和有序性的问题，而锁解决了原子性的问题，理想情况下我们希望做到“同步”和“互斥”。有以下常规实现方法：<br>将数据抽象成一个类，并将数据的操作作为这个类的方法 </p>
<ol>
<li><p>将数据抽象成一个类，并将对这个数据的操作作为这个类的方法，这么设计可以和容易做到<br>同步，只要在方法上加”synchronized“</p>
<p> public class MyData {<br>  private int j=0;<br> public synchronized void add(){<br>  j++;<br> System.out.println(“线程”+Thread.currentThread().getName()+”j 为：”+j);<br> }<br> public synchronized void dec(){<br>  j–;<br>  System.out.println(“线程”+Thread.currentThread().getName()+”j 为：”+j);<br>  }<br>  public int getData(){<br>  return j;<br>  }<br> }<br> public class AddRunnable implements Runnable{<br>  MyData data;<br>  public AddRunnable(MyData data){<br>  this.data= data;<br>  }<br> public void run() {<br>  data.add();<br>  }<br>  }<br> public class DecRunnable implements Runnable {<br>  MyData data;<br>  public DecRunnable(MyData data){<br>  this.data = data;<br>  }<br>  public void run() {<br>  data.dec();<br>  }<br> }<br>  public static void main(String[] args) {<br>  MyData data = new MyData();<br>  Runnable add = new AddRunnable(data);<br>  Runnable dec = new DecRunnable(data);<br>  for(int i=0;i&lt;2;i++){<br>  new Thread(add).start();<br>  new Thread(dec).start();<br>  } </p>
</li>
</ol>
<p>Runnable 对象作为一个类的内部类 </p>
<ol start="2">
<li><p>将 Runnable 对象作为一个类的内部类，共享数据作为这个类的成员变量，每个线程对共享数据的操作方法也封装在外部类，以便实现对数据的各个操作的同步和互斥，作为内部类的各个 Runnable 对象调用外部类的这些方法。</p>
<p> public class MyData {<br>  private int j=0;<br>  public synchronized void add(){<br>  j++;<br>  System.out.println(“线程”+Thread.currentThread().getName()+”j 为：”+j);<br>  }<br>  public synchronized void dec(){<br>  j–;<br>  System.out.println(“线程”+Thread.currentThread().getName()+”j 为：”+j);<br>  }<br>  public int getData(){<br>  return j; }<br> }<br> public class TestThread {<br>  public static void main(String[] args) {<br>  final MyData data = new MyData();<br>  for(int i=0;i&lt;2;i++){<br>  new Thread(new Runnable(){<br>  public void run() {<br>  data.add();<br>  }<br>  }).start();<br>  new Thread(new Runnable(){<br>  public void run() {<br>  data.dec();<br>  }<br>  }).start();<br>  }<br>  }<br> } </p>
</li>
</ol>
<p>4.1.18. ThreadLocal 作用（线程本地存储）<br>ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，ThreadLocal 的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。<br>ThreadLocalMap（线程的一个属性） </p>
<ol>
<li>每个线程中都有一个自己的 ThreadLocalMap 类对象，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。 </li>
<li>将一个共用的 ThreadLocal 静态实例作为 key，将不同对象的引用保存到不同线程的ThreadLocalMap 中，然后在线程执行的各处通过这个静态 ThreadLocal 实例的 get()方法取得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。 </li>
<li>ThreadLocalMap 其实就是线程里面的一个属性，它在 Thread 类中定义 ThreadLocal.ThreadLocalMap threadLocals = null;</li>
</ol>
<p>使用场景<br>最常见的 ThreadLocal 使用场景为 用来解决 数据库连接、Session 管理等。 </p>
<pre><code>private static final ThreadLocal threadSession = new ThreadLocal(); 
public static Session getSession() throws InfrastructureException &#123; 
 Session s = (Session) threadSession.get(); 
 try &#123; 
 if (s == null) &#123; 
 s = getSessionFactory().openSession(); 
 threadSession.set(s); 
 &#125; 
 &#125; catch (HibernateException ex) &#123; 
 throw new InfrastructureException(ex); 
 &#125; 
 return s; 
&#125; 
</code></pre>
<p>4.1.19. synchronized 和 ReentrantLock 的区别<br>4.1.19.1. 两者的共同点： </p>
<ol>
<li>都是用来协调多线程对共享对象、变量的访问 </li>
<li>都是可重入锁，同一线程可以多次获得同一个锁 </li>
<li>都保证了可见性和互斥性 </li>
</ol>
<p>4.1.19.2. 两者的不同点： </p>
<ol>
<li>ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁 </li>
<li>ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性 </li>
<li>ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的 </li>
<li>ReentrantLock 可以实现公平锁 </li>
<li>ReentrantLock 通过 Condition 可以绑定多个条件 </li>
<li>底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻塞，采用的是乐观并发策略 </li>
<li>Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现。 </li>
<li>synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。 </li>
<li>Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。 </li>
<li>通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 </li>
<li>Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。 </li>
</ol>
<p>4.1.20. ConcurrentHashMap 并发<br>4.1.20.1. 减小锁粒度 </p>
<p>减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是 ConcurrentHashMap(高性能的 HashMap)类的实现。对于 HashMap 而言，最重要的两个方法是 get 与 set 方法，如果我们对整个 HashMap 加锁，可以得到线程安全的对象，但是加锁粒度太大。Segment 的大小也被称为 ConcurrentHashMap 的并发度。 </p>
<p>4.1.20.2. ConcurrentHashMap 分段锁 </p>
<p>ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下一个 ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度。<br>如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首先根据 hashcode 得到该表项应该存放在哪个段中，然后对该段加锁，并完成 put 操作。在多线程环境中，如果多个线程同时进行 put操作，只要被加入的表项不存放在同一个段中，则线程间可以做到真正的并行。<br>ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成<br>ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。Segment 是一种可重入锁 ReentrantLock，在 ConcurrentHashMap 里扮演锁的角色，HashEntry 则用于存储键值对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的结构和 HashMap类似，是一种数组和链表结构， 一个 Segment 里包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素， 每个 Segment 守护一个 HashEntry 数组里的元素,当对 HashEntry 数组的数据进行修改时，必须首先获得它对应的 Segment 锁。</p>
<p>4.1.21. Java 中用到的线程调度<br>4.1.21.1. 抢占式调度：<br>抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。 </p>
<p>4.1.21.2. 协同式调度： </p>
<p>协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行，这种模式就像接力赛一样，一个人跑完自己的路程就把接力棒交接给下一个人，下个人继续往下跑。线程的执行时间由线程本身控制，线程切换可以预知，不存在多线程同步问题，但它有一个致命弱点：如果一个线程编写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃。  </p>
<p>4.1.21.3. JVM 的线程调度实现（抢占式调度） </p>
<p>java 使用的线程调使用抢占式调度，Java 中线程会按优先级分配 CPU 时间片运行，且优先级越高越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间片，反之，优先级低的分到的执行时间少但不会分配不到执行时间。 </p>
<p>4.1.21.4. 线程让出 cpu 的情况： </p>
<ol>
<li>当前运行线程主动放弃 CPU，JVM 暂时放弃 CPU 操作（基于时间片轮转调度的 JVM 操作系统不会让线程永久放弃 CPU，或者说放弃本次时间片的执行权），例如调用 yield()方法。 </li>
<li>当前运行线程因为某些原因进入阻塞状态，例如阻塞在 I/O 上。 </li>
<li>当前运行线程结束，即运行完 run()方法里面的任务。 </li>
</ol>
<p>4.1.22. 进程调度算法<br>4.1.22.1. 优先调度算法 </p>
<ol>
<li>先来先服务调度算法（FCFS）<br>当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机， 使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机，特点是：算法比较简单，可以实现基本上的公平。 </li>
<li>短作业(进程)优先调度算法<br>短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。该算法未照顾紧迫型作业。 </li>
</ol>
<p>4.1.22.2. 高优先权优先调度算法 </p>
<p>为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。 </p>
<ol>
<li>非抢占式优先权算法<br>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。 </li>
<li>抢占式优先权调度算法<br>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。<br>2．高响应比优先调度算法<br>在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行 得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时 间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的 变化规律可描述为：</li>
</ol>
<p> (1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于短作业。<br> (2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。<br> (3) 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。 </p>
<p>4.1.22.3. 基于时间片的轮转调度算法 </p>
<ol>
<li><p>时间片轮转法<br>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度 时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行 的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行， 并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执 行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处 理机执行时间。 </p>
</li>
<li><p>多级反馈队列调度算法<br>(1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二 个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各 不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的 时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要比第 i 个队列的时间片长 一倍。<br>(2) 当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度。当 轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时 尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果 它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个 长作业(进程)从第一队列依次降到第 n 队列后，在第 n 队列便采取按时间片轮转的方式运行。<br>(3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1)队列均空时， 才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时，又有新进程进入优 先权较高的队列(第 1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即 由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分配给新到的高优先权进程。  在多级反馈队列调度算法中，如果规定第一个队列的时间片略大于多数人机交互所需之处理时间 时，便能够较好的满足各种类型用户的需要。 </p>
</li>
</ol>
<p>4.1.23. 什么是 CAS（比较并交换-乐观锁机制-锁自旋）<br>4.1.23.1. 概念及特性 </p>
<p>CAS（Compare And Swap/Set）比较并交换，CAS 算法的过程是这样：它包含 3 个参数CAS(V,E,N)。V 表示要更新的变量(内存值)，E 表示预期值(旧的)，N 表示新值。<br>当且仅当 V 值等 于 E 值时，才会将 V 的值设为 N，如果 V 值和 E 值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS 返回当前 V 的真实值。<br>CAS 操作是抱着乐观的态度进行的(乐观锁)，它总是认为自己可以成功完成操作。当多个线程同时 使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂 起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理， CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。 </p>
<p>4.1.23.2. 原子包 java.util.concurrent.atomic（锁自旋） </p>
<p>JDK1.5 的原子包：java.util.concurrent.atomic 这个包里面提供了一组原子类。其基本的特性就 是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个 线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等 到该方法执行完成，才由 JVM 从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。 相对于对于 synchronized 这种阻塞算法，CAS 是非阻塞算法的一种常见实现。由于一般 CPU 切 换时间比 CPU 指令集操作更加长， 所以 J.U.C 在性能上有了很大的提升。如下代码：</p>
<pre><code>public class AtomicInteger extends Number implements java.io.Serializable &#123; 
 private volatile int value; 
public final int get() &#123; 
 return value; 
 &#125; 
 public final int getAndIncrement() &#123; 
 for (;;) &#123; //CAS 自旋，一直尝试，直达成功 
 int current = get(); 
 int next = current + 1; 
 if (compareAndSet(current, next)) 
 return current; 
 &#125; 
 &#125; 
 public final boolean compareAndSet(int expect, int update) &#123; 
 return unsafe.compareAndSwapInt(this, valueOffset, expect, update); 
 &#125; 
&#125; 
</code></pre>
<p>getAndIncrement 采用了 CAS 操作，每次从内存中读取数据然后将此数据和+1 后的结果进行 CAS 操作，如果成功就返回结果，否则重试直到成功为止。而 compareAndSet 利用 JNI 来完成 CPU 指令的操作。 </p>
<p> 4.1.23.3. ABA 问题 </p>
<p>CAS 会导致“ABA 问题”。CAS 算法实现一个重要前提需要取出内存中某时刻的数据，而在下时 刻比较并替换，那么在这个时间差类会导致数据的变化。<br>比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操 作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但是不代表这个过 程就是没有问题的。<br>部分乐观锁的实现是通过版本号（version）的方式来解决 ABA 问题，乐观锁每次在执行数据的修 改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本 号执行+1 操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问 题，因为版本号只会增加不会减少。 </p>
<p>4.1.24. 什么是 AQS（抽象的队列同步器）<br>AbstractQueuedSynchronizer 类如其名，抽象的队列式的同步器，AQS 定义了一套多线程访问 共享资源的同步器框架，许多同步类实现都依赖于它，如常用的 ReentrantLock/Semaphore/CountDownLatch。 </p>
<p>它维护了一个 volatile int state（代表共享资源）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会进入此队列）。这里 volatile 是核心关键词，具体 volatile 的语义，在此不述。state 的访问方式有三种:<br>    getState()<br>    setState()<br>    compareAndSetState() </p>
<p>AQS 定义两种资源共享方式<br>    Exclusive 独占资源-ReentrantLock<br>    Exclusive（独占，只有一个线程能执行，如 ReentrantLock）<br>    Share 共享资源-Semaphore/CountDownLatch<br>    Share（共享，多个线程可同时执行，如 Semaphore/CountDownLatch）。 </p>
<p>AQS 只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现，AQS 这里只定义了一个 接口，具体资源的获取交由自定义同步器去实现了（通过 state 的 get/set/CAS)之所以没有定义成 abstract ，是因为独占模式下只用实现 tryAcquire-tryRelease ，而共享模式下只用实现 tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模 式下的接口。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实 现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/ 唤醒出队等），AQS 已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： </p>
<p>1． isHeldExclusively()：该线程是否正在独占资源。只有用到 condition 才需要去实现它。<br>2． tryAcquire(int)：独占方式。尝试获取资源，成功则返回 true，失败则返回 false。<br>3． tryRelease(int)：独占方式。尝试释放资源，成功则返回 true，失败则返回 false。<br>4． tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0 表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。<br>5． tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回 false。 </p>
<p>同步器的实现是 ABS 核心（state 资源状态计数）<br>同步器的实现是 ABS 核心，以 ReentrantLock 为例，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失 败，直到 A 线程 unlock()到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放 锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意， 获取多少次就要释放多么次，这样才能保证 state 是能回到零态的。<br>以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与 线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后 countDown()一次，state 会 CAS 减 1。等到所有子线程都执行完后(即 state=0)，会 unpark()主调用线程，然后主调用线程 就会从 await()函数返回，继续后余动作。<br>ReentrantReadWriteLock 实现独占和共享两种方式<br>————————————————<br>版权声明：本文为CSDN博主「Y·C」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_54853465/article/details/125463693">https://blog.csdn.net/m0_54853465/article/details/125463693</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/JAVA/" rel="tag">JAVA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Thread/" rel="tag">Thread</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/38/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/">37</a><a class="page-number" href="/page/38/">38</a><span class="page-number current">39</span><a class="page-number" href="/page/40/">40</a><a class="page-number" href="/page/41/">41</a><span class="space">&hellip;</span><a class="page-number" href="/page/55/">55</a><a class="extend next" rel="next" href="/page/40/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2022-2024
        <i class="ri-heart-fill heart_icon"></i> paladin1893
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="帕拉丁的游鱼"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>